{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a84cff6",
   "metadata": {},
   "source": [
    "###  Baseline Multimodal Model: Early Fusion (ResNet50 + DeBERTa)\n",
    "\n",
    "This notebook establishes our baseline multimodal model for stance classification.\n",
    "\n",
    "Architecture:\n",
    "  - Text Branch:  DeBERTa\n",
    "  - Image Branch: ResNet50 \n",
    "  - Fusion:       Early Fusion (concatenate embeddings)\n",
    "  - Classifier:   MLP\n",
    "\n",
    "Strategy:\n",
    "  - No data augmentation (raw data)\n",
    "  - No gating mechanism (all images used)\n",
    "  - Simple concatenation fusion\n",
    "  - Standard hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "276ab224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  42\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score,f1_score, precision_score, recall_score,confusion_matrix, classification_report\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel,get_linear_schedule_with_warmup,AutoModelForSequenceClassification\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Random seed for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Seed:  {SEED}\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1cf6b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train label distribution:\n",
      "\n",
      " Stance: \n",
      " Oppose: 1095\n",
      " Support: 719\n",
      "\n",
      "\n",
      "  Persuasiveness \n",
      " No: 1285\n",
      " Yes: 529\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>stance</th>\n",
       "      <th>persuasiveness</th>\n",
       "      <th>split</th>\n",
       "      <th>label</th>\n",
       "      <th>persuasiveness_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1148501065308004357</td>\n",
       "      <td>https://t.co/VQP1FHaWAg</td>\n",
       "      <td>Let's McGyver some Sanity in America!\\n\\nYou a...</td>\n",
       "      <td>support</td>\n",
       "      <td>no</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1103872992537276417</td>\n",
       "      <td>https://t.co/zsyXYSeBkp</td>\n",
       "      <td>A child deserves a chance at life. A child des...</td>\n",
       "      <td>oppose</td>\n",
       "      <td>no</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1151528583623585794</td>\n",
       "      <td>https://t.co/qSWvDX5MnM</td>\n",
       "      <td>Dear prolifers: girls as young as 10, 11, 12 a...</td>\n",
       "      <td>support</td>\n",
       "      <td>no</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1100166844026109953</td>\n",
       "      <td>https://t.co/hxH8tFIHUu</td>\n",
       "      <td>The many States will attempt to amend their co...</td>\n",
       "      <td>support</td>\n",
       "      <td>no</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1021830413550067713</td>\n",
       "      <td>https://t.co/5whvEEtoQR</td>\n",
       "      <td>Every #abortion is wrong, no matter what metho...</td>\n",
       "      <td>oppose</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                tweet_url  \\\n",
       "0  1148501065308004357  https://t.co/VQP1FHaWAg   \n",
       "1  1103872992537276417  https://t.co/zsyXYSeBkp   \n",
       "2  1151528583623585794  https://t.co/qSWvDX5MnM   \n",
       "3  1100166844026109953  https://t.co/hxH8tFIHUu   \n",
       "4  1021830413550067713  https://t.co/5whvEEtoQR   \n",
       "\n",
       "                                          tweet_text   stance persuasiveness  \\\n",
       "0  Let's McGyver some Sanity in America!\\n\\nYou a...  support             no   \n",
       "1  A child deserves a chance at life. A child des...   oppose             no   \n",
       "2  Dear prolifers: girls as young as 10, 11, 12 a...  support             no   \n",
       "3  The many States will attempt to amend their co...  support             no   \n",
       "4  Every #abortion is wrong, no matter what metho...   oppose            yes   \n",
       "\n",
       "   split  label  persuasiveness_label  \n",
       "0  train      1                     0  \n",
       "1  train      0                     0  \n",
       "2  train      1                     0  \n",
       "3  train      1                     0  \n",
       "4  train      0                     1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Paths\n",
    "DATA_PATH = \"../../data/\"\n",
    "IMG_PATH = \"../../data/images\"\n",
    "OUTPUT_DIR = \"../../results/multimodal/baseline_multimodal/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "train_path = os.path.join(DATA_PATH,\"train.csv\")\n",
    "dev_path   = os.path.join(DATA_PATH,\"dev.csv\")\n",
    "test_path  = os.path.join(DATA_PATH,\"test.csv\")\n",
    "\n",
    "#Load Data\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_dev   = pd.read_csv(dev_path)\n",
    "df_test  = pd.read_csv(test_path)\n",
    "\n",
    "# Map labels to ints\n",
    "stance_2id = {\"oppose\": 0, \"support\": 1}\n",
    "pers_2id = {\"no\": 0, \"yes\": 1}\n",
    "\n",
    "for df in [df_train, df_dev, df_test]:\n",
    "    df[\"label\"] = df[\"stance\"].map(stance_2id)\n",
    "    df[\"persuasiveness_label\"] = df[\"persuasiveness\"].map(pers_2id)\n",
    "\n",
    "\n",
    "print(f\"\\n Train label distribution:\")\n",
    "print(f\"\\n Stance: \\n Oppose: {(df_train['label']==0).sum()}\\n Support: {(df_train['label']==1).sum()}\")\n",
    "print(f\"\\n\\n  Persuasiveness \\n No: {(df_train['persuasiveness_label']==0).sum()}\\n Yes: {(df_train['persuasiveness_label']==1).sum()}\")\n",
    "\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5c180ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models\n",
    "TEXT_MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
    "VISION_MODEL_NAME = \"resnet50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c1a98a3-a727-4f06-8501-dcfad8ee334f",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Training hyperparameters\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 15\n",
    "LEARNING_RATE = 2e-5\n",
    "WEIGHT_DECAY = 1e-4\n",
    "WARMUP_RATIO = 0.1\n",
    "\n",
    "# Early stopping\n",
    "PATIENCE = 5\n",
    "\n",
    "# Image preprocessing\n",
    "IMG_SIZE = 224\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Text preprocessing\n",
    "MAX_TEXT_LENGTH = 105\n",
    "\n",
    "# Other\n",
    "NUM_WORKERS = 1\n",
    "PIN_MEMORY = True if torch.cuda.is_available() else False\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdb7101",
   "metadata": {},
   "source": [
    "###  Multimodal Dataset\n",
    "We create a MultimodalDataset that will return:\n",
    "- tokenized text (input_ids, attention_mask)\n",
    "- image tensor (transforms applied)\n",
    "- label (stance)\n",
    "\n",
    "We will handle corrupted images safely (blank image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98beadeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMG_MEAN, std=IMG_STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ab2f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset that returns (image, text, label) for multimodal learning.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dataframe: pd.DataFrame,\n",
    "        img_dir: str,\n",
    "        tokenizer,\n",
    "        image_transform,\n",
    "        max_length: int = 128\n",
    "    ):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.tokenizer = tokenizer\n",
    "        self.image_transform = image_transform\n",
    "        self.max_length = max_length\n",
    "        \n",
    "\n",
    "        # We calculate class distribution\n",
    "        self.class_counts = self.df['label'].value_counts().to_dict()\n",
    "        self.num_samples = len(self.df)\n",
    "\n",
    "        print(f\"  Dataset created: {self.num_samples} samples\")\n",
    "        print(f\"    - Class 0 (oppose):  {self.class_counts.get(0, 0)} samples\")\n",
    "        print(f\"    - Class 1 (support): {self.class_counts.get(1, 0)} samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # Load Image\n",
    "        img_path = os.path.join(self.img_dir, str(row['tweet_id']) + \".jpg\")\n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            image = self.image_transform(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: could not load image {img_path}. Using grey image instead.\")\n",
    "            image = Image.new(\"RGB\", (224, 224), color=(128, 128, 128))\n",
    "            image = self.image_transform(image)\n",
    "        \n",
    "        # Load Text and Tokenize \n",
    "        text = str(row['tweet_text'])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Our Label\n",
    "        label = row['label']\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(label, dtype=torch.long),\n",
    "            'tweet_id': str(row['tweet_id']),\n",
    "            'text': text\n",
    "        }\n",
    "    \n",
    "    #Attribute to calculate class weights\n",
    "    def get_class_weights(self, device):\n",
    "        num_class_0 = self.class_counts.get(0, 0)\n",
    "        num_class_1 = self.class_counts.get(1, 0)\n",
    "        total = self.num_samples\n",
    "        \n",
    "        weights = torch.tensor([\n",
    "            total / num_class_0 if num_class_0 > 0 else 1.0,\n",
    "            total / num_class_1 if num_class_1 > 0 else 1.0], dtype=torch.float32).to(device)\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acc0de10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded: microsoft/deberta-v3-base\n"
     ]
    }
   ],
   "source": [
    "# Load Tokenized\n",
    "tokenizer = AutoTokenizer.from_pretrained(TEXT_MODEL_NAME)\n",
    "print(f\"Tokenizer loaded: {TEXT_MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82312c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dataset created: 1814 samples\n",
      "    - Class 0 (oppose):  1095 samples\n",
      "    - Class 1 (support): 719 samples\n",
      "  Dataset created: 200 samples\n",
      "    - Class 0 (oppose):  127 samples\n",
      "    - Class 1 (support): 73 samples\n",
      "  Dataset created: 300 samples\n",
      "    - Class 0 (oppose):  182 samples\n",
      "    - Class 1 (support): 118 samples\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_dataset = MultimodalDataset(df_train, IMG_PATH, tokenizer, image_transforms, MAX_TEXT_LENGTH)\n",
    "dev_dataset = MultimodalDataset(df_dev, IMG_PATH, tokenizer, image_transforms, MAX_TEXT_LENGTH)\n",
    "test_dataset = MultimodalDataset(df_test, IMG_PATH, tokenizer, image_transforms, MAX_TEXT_LENGTH)\n",
    "\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=NUM_WORKERS,pin_memory=True)\n",
    "dev_loader = DataLoader(dev_dataset,batch_size=BATCH_SIZE,shuffle=False,num_workers=NUM_WORKERS,pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=False,num_workers=NUM_WORKERS,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfe4a5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Image shape: torch.Size([3, 224, 224])\n",
      "  Input IDs shape: torch.Size([105])\n",
      "  Label: 1\n",
      "  Text (truncated): Let's McGyver some Sanity in America!\n",
      "\n",
      "You are not pro-life if you lock children in cages, deny them lunch at school, or cut programs for the disabled!\n",
      "\n",
      "And, good Christians don't applaud rapists, con men, &amp; hate!\n",
      "\n",
      "Hate Fixes NADDA! It just creates more problems!\n",
      "\n",
      "ðŸ§°ðŸ“ðŸ”Žâ›ï¸ðŸ”§ðŸ› ï¸ðŸ§° https://t.co/VQP1FHaWAg\n"
     ]
    }
   ],
   "source": [
    "#We test our datasets and loaders\n",
    "sample = train_dataset[0]\n",
    "print(f\"  Image shape: {sample['image'].shape}\")\n",
    "print(f\"  Input IDs shape: {sample['input_ids'].shape}\")\n",
    "print(f\"  Label: {sample['label'].item()}\")\n",
    "print(f\"  Text (truncated): {sample['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c69a3148",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalBaseline(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        text_model_name=\"microsoft/deberta-v3-base\",\n",
    "        vision_model_name=\"resnet50\",\n",
    "        num_classes=2,\n",
    "        freeze_text=False,\n",
    "        freeze_vision=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # TEXT\n",
    "        print(f\"Loading TEXT encoder: {text_model_name}\")\n",
    "        self.text_encoder = AutoModel.from_pretrained(text_model_name)\n",
    "        self.text_hidden = self.text_encoder.config.hidden_size\n",
    "\n",
    "        if freeze_text:\n",
    "            for p in self.text_encoder.parameters():\n",
    "                p.requires_grad = False\n",
    "            print(\"Text encoder FROZEN\")\n",
    "\n",
    "        # VISION\n",
    "        print(f\"Loading VISION encoder: {vision_model_name}\")\n",
    "        self.vision_encoder = models.resnet50(pretrained=True)\n",
    "        self.vision_encoder = nn.Sequential(*list(self.vision_encoder.children())[:-1])\n",
    "        self.vision_hidden = 2048\n",
    "\n",
    "        if freeze_vision:\n",
    "            for p in self.vision_encoder.parameters():\n",
    "                p.requires_grad = False\n",
    "            print(\"Vision encoder FROZEN\")\n",
    "\n",
    "        # We project our vision embeddings\n",
    "        self.vision_proj = nn.Linear(self.vision_hidden, self.text_hidden)\n",
    "\n",
    "        # CLASSIFIER\n",
    "        self.classifier = nn.Linear(self.text_hidden * 2, num_classes)\n",
    "\n",
    "        print(\"Multimodal baseline initialized.\")\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, images=None, mode=\"multimodal\"):\n",
    "        \n",
    "        # Text embeddings\n",
    "        text_out = self.text_encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        text_emb = text_out.last_hidden_state[:, 0, :]  # CLS\n",
    "\n",
    "        # We add the Vision embeddings if Multimodal\n",
    "        if mode == \"multimodal\":\n",
    "            vision_feat = self.vision_encoder(images)\n",
    "            vision_feat = vision_feat.squeeze(-1).squeeze(-1)\n",
    "            vision_emb = self.vision_proj(vision_feat)\n",
    "        else:\n",
    "            vision_emb = torch.zeros_like(text_emb)\n",
    "\n",
    "        # Early Fusion\n",
    "        fused = torch.cat([text_emb, vision_emb], dim=1)\n",
    "        logits = self.classifier(fused)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a2c009-0159-4dd9-bea5-56edcd35a2c8",
   "metadata": {},
   "source": [
    "#### Sanity Check (Forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffd249f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TEXT encoder: microsoft/deberta-v3-base\n",
      "Loading VISION encoder: resnet50\n",
      "Vision encoder FROZEN\n",
      "Multimodal baseline initialized correctly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "model = MultimodalBaseline(\n",
    "    text_model_name=TEXT_MODEL_NAME,\n",
    "    num_classes=2,\n",
    "    freeze_text=False,\n",
    "    freeze_vision=True).to(DEVICE)\n",
    "\n",
    "model.eval()\n",
    "sample_batch = next(iter(train_loader))\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(\n",
    "        input_ids=sample_batch[\"input_ids\"][:2].to(DEVICE),\n",
    "        attention_mask=sample_batch[\"attention_mask\"][:2].to(DEVICE),\n",
    "        images=None,\n",
    "        mode=\"multimodal\"\n",
    "    )\n",
    "\n",
    "print(\"Logits shape:\", logits.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b48d97",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81d89ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_text_only_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    dev_loader,\n",
    "    num_epochs=5,\n",
    "    learning_rate=2e-5,\n",
    "    patience=2,\n",
    "    device=DEVICE):\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_f1 = 0.0\n",
    "    best_model_state = None\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_f1\": [],\n",
    "        \"dev_loss\": [],\n",
    "        \"dev_f1\": []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_preds = []\n",
    "        train_labels = []\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            logits = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                mode=\"text_only\"\n",
    "            )\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * labels.size(0)\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_f1 = f1_score(train_labels, train_preds, average=\"binary\", pos_label=1)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        dev_loss = 0.0\n",
    "        dev_preds = []\n",
    "        dev_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dev_loader, desc=\"Validation\", leave=False):\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"label\"].to(device)\n",
    "\n",
    "                logits = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    mode=\"text_only\"\n",
    "                )\n",
    "\n",
    "                loss = criterion(logits, labels)\n",
    "                dev_loss += loss.item() * labels.size(0)\n",
    "\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                dev_preds.extend(preds.cpu().numpy())\n",
    "                dev_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        dev_loss /= len(dev_loader.dataset)\n",
    "        dev_f1 = f1_score(dev_labels, dev_preds, average=\"binary\", pos_label=1)\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_f1\"].append(train_f1)\n",
    "        history[\"dev_loss\"].append(dev_loss)\n",
    "        history[\"dev_f1\"].append(dev_f1)\n",
    "\n",
    "        print(f\"TRAIN â†’ Loss: {train_loss:.4f} | F1: {train_f1:.4f}\")\n",
    "        print(f\"DEV   â†’ Loss: {dev_loss:.4f} | F1: {dev_f1:.4f}\")\n",
    "\n",
    "        # Early Stopping\n",
    "        if dev_f1 > best_f1:\n",
    "            best_f1 = dev_f1\n",
    "            best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            epochs_no_improve = 0\n",
    "            print(f\" New best DEV F1: {best_f1:.4f}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement for {epochs_no_improve} epoch(s)\")\n",
    "\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(\" Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_model_state)\n",
    "    model = model.to(device)\n",
    "\n",
    "    print(f\"\\nBest DEV F1: {best_f1:.4f}\")\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f81476ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multimodal_model(\n",
    "    model, \n",
    "    train_loader, \n",
    "    dev_loader,\n",
    "    num_epochs=15, \n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=1e-4, \n",
    "    warmup_ratio=0.1,\n",
    "    mode=\"multimodal\",\n",
    "    patience=5, \n",
    "    device=DEVICE):\n",
    "    \n",
    "    model = model.to(device)\n",
    "\n",
    "    # Class Weights (If data unblanced)\n",
    "    class_weights = train_loader.dataset.get_class_weights(device)\n",
    "    print(f\"Class weights: oppose={class_weights[0]:.3f}, support={class_weights[1]:.3f}\")\n",
    "\n",
    "    # Loss\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "\n",
    "    # Scheduler \n",
    "    num_training_steps = len(train_loader) * num_epochs\n",
    "    num_warmup_steps = int(num_training_steps * warmup_ratio)\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=num_warmup_steps,num_training_steps=num_training_steps)\n",
    "    print(f\"Total training steps: {num_training_steps}\")\n",
    "    print(f\"Warmup steps: {num_warmup_steps}\")\n",
    "\n",
    "    #  History \n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_f1\": [],\n",
    "        \"dev_loss\": [],\n",
    "        \"dev_f1\": [],\n",
    "        \"learning_rates\": []\n",
    "    }\n",
    "\n",
    "    #  Early stopping \n",
    "    best_f1 = 0.0\n",
    "    best_model_state = None\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    # OUR TRAINING LOOP\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_preds = []\n",
    "        train_labels = []\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            images = batch[\"image\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            logits = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                images=images,\n",
    "                mode=mode)\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            train_loss += loss.item() * labels.size(0)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_f1 = f1_score(train_labels, train_preds, average=\"binary\", pos_label=1)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        dev_loss = 0.0\n",
    "        dev_preds = []\n",
    "        dev_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dev_loader, desc=\"Validation\", leave=False):\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                images = batch[\"image\"].to(device)\n",
    "                labels = batch[\"label\"].to(device)\n",
    "\n",
    "                logits = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    images=images,\n",
    "                    mode=mode)\n",
    "\n",
    "                loss = criterion(logits, labels)\n",
    "                dev_loss += loss.item() * labels.size(0)\n",
    "\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                dev_preds.extend(preds.cpu().numpy())\n",
    "                dev_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        dev_loss /= len(dev_loader.dataset)\n",
    "        dev_f1 = f1_score(dev_labels, dev_preds, average=\"binary\", pos_label=1)\n",
    "\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_f1\"].append(train_f1)\n",
    "        history[\"dev_loss\"].append(dev_loss)\n",
    "        history[\"dev_f1\"].append(dev_f1)\n",
    "        history[\"learning_rates\"].append(current_lr)\n",
    "\n",
    "        print(f\"TRAIN LOSS: {train_loss:.4f} | F1: {train_f1:.4f}\")\n",
    "        print(f\"DEV LOSS: {dev_loss:.4f} | F1: {dev_f1:.4f}\")\n",
    "        print(f\"LR: {current_lr:.2e}\")\n",
    "\n",
    "        # Early Stopping\n",
    "        if dev_f1 > best_f1:\n",
    "            best_f1 = dev_f1\n",
    "            best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            epochs_without_improvement = 0\n",
    "            print(f\"  New best Dev F1: {best_f1:.4f}\")\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            print(f\"No improvement for {epochs_without_improvement} epoch(s)\")\n",
    "\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(\"\\n  Early stopping triggered!\")\n",
    "                break\n",
    "\n",
    "    # Load Best Model\n",
    "    model.load_state_dict(best_model_state)\n",
    "    model = model.to(device)\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training complete!\")\n",
    "    print(f\"Best Dev F1 (pos=1): {best_f1:.4f}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33229cbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING TEXT-ONLY MULTIMODAL BASELINE\n",
      "Loading TEXT encoder: microsoft/deberta-v3-base\n",
      "Loading VISION encoder: resnet50\n",
      "Vision encoder FROZEN\n",
      "Multimodal baseline initialized correctly\n",
      "\n",
      "============================================================\n",
      "Epoch 1/5\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f19294b6cd84579a9818814b24b9f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN â†’ Loss: 0.4615 | F1: 0.6104\n",
      "DEV   â†’ Loss: 0.2334 | F1: 0.8613\n",
      " New best DEV F1: 0.8613\n",
      "\n",
      "============================================================\n",
      "Epoch 2/5\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be33ca8c5edc46edb40b4ffd86269697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN â†’ Loss: 0.2020 | F1: 0.8997\n",
      "DEV   â†’ Loss: 0.1588 | F1: 0.9118\n",
      " New best DEV F1: 0.9118\n",
      "\n",
      "============================================================\n",
      "Epoch 3/5\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9061b56afdf2485a87afaa8004f10b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN â†’ Loss: 0.1123 | F1: 0.9480\n",
      "DEV   â†’ Loss: 0.2175 | F1: 0.8955\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "============================================================\n",
      "Epoch 4/5\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ac30bf13da4c25989d1d43c5c8515f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN â†’ Loss: 0.0589 | F1: 0.9750\n",
      "DEV   â†’ Loss: 0.2148 | F1: 0.9014\n",
      "No improvement for 2 epoch(s)\n",
      " Early stopping triggered\n",
      "\n",
      "Best DEV F1: 0.9118\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAINING TEXT-ONLY MULTIMODAL BASELINE\")\n",
    "\n",
    "text_model = MultimodalBaseline(\n",
    "    text_model_name=TEXT_MODEL_NAME,\n",
    "    num_classes=2,\n",
    "    freeze_text=False)\n",
    "\n",
    "model_text, history_text = train_text_only_model(\n",
    "    model=text_model,\n",
    "    train_loader=train_loader,\n",
    "    dev_loader=dev_loader,\n",
    "    num_epochs=5,\n",
    "    learning_rate=2e-5,\n",
    "    patience=2,\n",
    "    device=DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9647e92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MULTIMODAL MODEL\n",
      "Loading TEXT encoder: microsoft/deberta-v3-base\n",
      "Loading VISION encoder: resnet50\n",
      "Vision encoder FROZEN\n",
      "Multimodal baseline initialized correctly\n",
      "Class weights: oppose=1.657, support=2.523\n",
      "Total training steps: 1710\n",
      "Warmup steps: 171\n",
      "\n",
      "============================================================\n",
      "Epoch 1/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8815866619f044f8b176ec0ea4e24776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN â†’ Loss: 0.6791 | F1: 0.5363\n",
      "DEV   â†’ Loss: 0.4933 | F1: 0.6861\n",
      "LR    â†’ 1.33e-05\n",
      "ðŸ”¥ New best Dev F1: 0.6861\n",
      "\n",
      "============================================================\n",
      "Epoch 2/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a4178bf842410a8ecb96f1c7b818b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN â†’ Loss: 0.3804 | F1: 0.8089\n",
      "DEV   â†’ Loss: 0.2741 | F1: 0.8333\n",
      "LR    â†’ 1.93e-05\n",
      "ðŸ”¥ New best Dev F1: 0.8333\n",
      "\n",
      "============================================================\n",
      "Epoch 3/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed3e90d8f194afdbe2512a78790be2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN â†’ Loss: 0.1907 | F1: 0.9249\n",
      "DEV   â†’ Loss: 0.2917 | F1: 0.8571\n",
      "LR    â†’ 1.78e-05\n",
      "ðŸ”¥ New best Dev F1: 0.8571\n",
      "\n",
      "============================================================\n",
      "Epoch 4/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48bb0d3bbcd847d6ab6e9361e0832e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN â†’ Loss: 0.1286 | F1: 0.9544\n",
      "DEV   â†’ Loss: 0.4228 | F1: 0.8590\n",
      "LR    â†’ 1.63e-05\n",
      "ðŸ”¥ New best Dev F1: 0.8590\n",
      "\n",
      "============================================================\n",
      "Epoch 5/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e1875cc5204b199b4c791a95ef12a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN â†’ Loss: 0.0564 | F1: 0.9806\n",
      "DEV   â†’ Loss: 0.4943 | F1: 0.8857\n",
      "LR    â†’ 1.48e-05\n",
      "ðŸ”¥ New best Dev F1: 0.8857\n",
      "\n",
      "============================================================\n",
      "Epoch 6/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511e3546b9f147f38a824b8999ff7a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN â†’ Loss: 0.0289 | F1: 0.9917\n",
      "DEV   â†’ Loss: 0.5452 | F1: 0.8571\n",
      "LR    â†’ 1.33e-05\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "============================================================\n",
      "Epoch 7/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48963fd89aff412a8207b26a5de73a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN â†’ Loss: 0.0223 | F1: 0.9931\n",
      "DEV   â†’ Loss: 0.6286 | F1: 0.8841\n",
      "LR    â†’ 1.19e-05\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "============================================================\n",
      "Epoch 8/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa43841692d419d953d2788a01c4359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN â†’ Loss: 0.0091 | F1: 0.9965\n",
      "DEV   â†’ Loss: 0.6150 | F1: 0.8714\n",
      "LR    â†’ 1.04e-05\n",
      "No improvement for 3 epoch(s)\n",
      "\n",
      "============================================================\n",
      "Epoch 9/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07d9302b04f45bea7a61e4a9c4bcf66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "        self._shutdown_workers()\n",
      "self._shutdown_workers()  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "\n",
      "      File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "if w.is_alive():    \n",
      "if w.is_alive():  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "      File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError\n",
      ": AssertionErrorcan only test a child process: \n",
      "can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "      File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "self._shutdown_workers()    \n",
      "self._shutdown_workers()  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "\n",
      "      File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "if w.is_alive():    \n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "if w.is_alive():    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "    AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process': \n",
      "can only test a child processAssertionError\n",
      ": can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "\n",
      "    Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "self._shutdown_workers()    \n",
      "self._shutdown_workers()  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "\n",
      "      File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "if w.is_alive():    \n",
      "if w.is_alive():  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "      File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError\n",
      ": AssertionErrorcan only test a child process: \n",
      "can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "      File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "self._shutdown_workers()    \n",
      "self._shutdown_workers()  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "\n",
      "      File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "if w.is_alive():    \n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "if w.is_alive():    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "    AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process': \n",
      "can only test a child processAssertionError\n",
      ": can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in:   File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>    \n",
      "self._shutdown_workers()Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "        self._shutdown_workers()\n",
      "if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    if w.is_alive():    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "AssertionError    assert self._parent_pid == os.getpid(), 'can only test a child process': can only test a child process\n",
      "AssertionError\n",
      ": can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN â†’ Loss: 0.0204 | F1: 0.9951\n",
      "DEV   â†’ Loss: 0.5452 | F1: 0.8857\n",
      "LR    â†’ 8.89e-06\n",
      "No improvement for 4 epoch(s)\n",
      "\n",
      "============================================================\n",
      "Epoch 10/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a18afa2675b4fd3bb7d578e8a9a6a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb426259870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN â†’ Loss: 0.0068 | F1: 0.9979\n",
      "DEV   â†’ Loss: 0.7148 | F1: 0.8824\n",
      "LR    â†’ 7.41e-06\n",
      "No improvement for 5 epoch(s)\n",
      "\n",
      "â¹ Early stopping triggered!\n",
      "\n",
      "============================================================\n",
      "Training complete!\n",
      "Best Dev F1 (pos=1): 0.8857\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAINING MULTIMODAL MODEL\")\n",
    "\n",
    "model = MultimodalBaseline(\n",
    "    text_model_name=TEXT_MODEL_NAME,\n",
    "    num_classes=2,\n",
    "    freeze_text=False,\n",
    "    freeze_vision=True)\n",
    "\n",
    "model, history = train_multimodal_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    dev_loader=dev_loader,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    mode=\"multimodal\",\n",
    "    patience=PATIENCE,\n",
    "    device=DEVICE\n",
    ")\n",
    "#model_save_path = os.path.join(OUTPUT_DIR, \"multimodal_baseline_best.pth\")\n",
    "#torch.save(model.state_dict(), model_save_path)\n",
    "#print(f\"\\nModel saved at: {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a99955",
   "metadata": {},
   "source": [
    "### Evaluation (Test Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51d40764-88ef-4191-b91a-44ae0e25b98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,dataloader,threshold=0.5,mode=\"multimodal\",device=\"cuda\",verbose=True):\n",
    "    \n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\", disable=not verbose):\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            images = batch[\"image\"].to(device)\n",
    "\n",
    "\n",
    "            #Text Only\n",
    "            if mode==\"text_only\":\n",
    "                logits = model(input_ids=input_ids,\n",
    "                               attention_mask=attention_mask,\n",
    "                               images=None,\n",
    "                               mode=mode)\n",
    "                \n",
    "            #Multimodal\n",
    "            else:\n",
    "                logits = model(input_ids=input_ids,\n",
    "                           attention_mask=attention_mask,\n",
    "                           images=images,\n",
    "                           mode=mode)\n",
    "\n",
    "            probs = torch.softmax(logits, dim=1)[:, 1]\n",
    "            preds = (probs >= threshold).long()\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Convert to numpy\n",
    "    y_true = np.array(all_labels)\n",
    "    y_pred = np.array(all_preds)\n",
    "    y_prob = np.array(all_probs)\n",
    "\n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average=\"binary\", pos_label=1)\n",
    "    precision = precision_score(y_true, y_pred, average=\"binary\", pos_label=1, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average=\"binary\", pos_label=1)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': cm,\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred,\n",
    "        'y_prob': y_prob,\n",
    "        'threshold': threshold\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bc0589f-f56b-4875-bb67-060bc3cee5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT MODEL - TEST RESULTS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.8258\n",
      "Precision: 0.7466\n",
      "Recall:    0.9237\n",
      "Accuracy:  0.8467\n"
     ]
    }
   ],
   "source": [
    "print(\"TEXT MODEL - TEST RESULTS\")\n",
    "test_results = evaluate_model(model, test_loader, threshold=0.5, device=DEVICE, verbose=False,mode=\"multimodal\")\n",
    "print(f\"F1 Score:  {test_results['f1']:.4f}\")\n",
    "print(f\"Precision: {test_results['precision']:.4f}\")\n",
    "print(f\"Recall:    {test_results['recall']:.4f}\")\n",
    "print(f\"Accuracy:  {test_results['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c22eb25e-34bb-4e36-91a8-e3ac9ac082ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MULTIMODAL MODEL - TEST RESULTS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.8240\n",
      "Precision: 0.7383\n",
      "Recall:    0.9322\n",
      "Accuracy:  0.8433\n"
     ]
    }
   ],
   "source": [
    "print(\"MULTIMODAL MODEL - TEST RESULTS\")\n",
    "\n",
    "test_results = evaluate_model(model, test_loader, threshold=0.5, device=DEVICE, verbose=False,mode=\"text_only\")\n",
    "print(f\"F1 Score:  {test_results['f1']:.4f}\")\n",
    "print(f\"Precision: {test_results['precision']:.4f}\")\n",
    "print(f\"Recall:    {test_results['recall']:.4f}\")\n",
    "print(f\"Accuracy:  {test_results['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee9bbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Trainning Curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "# Loss curves\n",
    "axes[0, 0].plot(epochs, history['train_loss'], label='Train Loss', marker='o', linewidth=2)\n",
    "axes[0, 0].plot(epochs, history['dev_loss'], label='Dev Loss', marker='s', linewidth=2)\n",
    "axes[0, 0].set_title('Loss Curves', fontweight='bold', fontsize=14)\n",
    "axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0, 0].legend(fontsize=11)\n",
    "axes[0, 0].grid(alpha=0.3, linestyle='--')\n",
    "# Best Epoch\n",
    "best_epoch = np.argmin(history['dev_loss']) + 1\n",
    "axes[0, 0].axvline(x=best_epoch, color='red', linestyle='--', alpha=0.5, label=f'Best (epoch {best_epoch})')\n",
    "axes[0, 0].legend(fontsize=11)\n",
    "\n",
    "# F1 curves\n",
    "axes[0, 1].plot(epochs, history['train_f1'], label='Train F1', marker='o', linewidth=2)\n",
    "axes[0, 1].plot(epochs, history['dev_f1'], label='Dev F1', marker='s', linewidth=2)\n",
    "axes[0, 1].set_title('F1 Score Curves', fontweight='bold', fontsize=14)\n",
    "axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 1].set_ylabel('F1 Score (Binary, pos=1)', fontsize=12)\n",
    "axes[0, 1].legend(fontsize=11)\n",
    "axes[0, 1].grid(alpha=0.3, linestyle='--')\n",
    "axes[0, 1].set_ylim([0, 1])  \n",
    "# Best Epoch\n",
    "best_epoch_f1 = np.argmax(history['dev_f1']) + 1\n",
    "axes[0, 1].axvline(x=best_epoch_f1, color='red', linestyle='--', alpha=0.5, label=f'Best (epoch {best_epoch_f1})')\n",
    "axes[0, 1].legend(fontsize=11)\n",
    "\n",
    "# Precision & Recall curves \n",
    "if 'train_precision' in history and 'train_recall' in history:\n",
    "    axes[1, 0].plot(epochs, history['train_precision'], label='Train Precision', marker='o', linewidth=2, alpha=0.7)\n",
    "    axes[1, 0].plot(epochs, history['dev_precision'], label='Dev Precision', marker='s', linewidth=2, alpha=0.7)\n",
    "    axes[1, 0].plot(epochs, history['train_recall'], label='Train Recall', marker='^', linewidth=2, alpha=0.7)\n",
    "    axes[1, 0].plot(epochs, history['dev_recall'], label='Dev Recall', marker='v', linewidth=2, alpha=0.7)\n",
    "    axes[1, 0].set_title('Precision & Recall', fontweight='bold', fontsize=14)\n",
    "    axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('Score', fontsize=12)\n",
    "    axes[1, 0].legend(fontsize=10, loc='best')\n",
    "    axes[1, 0].grid(alpha=0.3, linestyle='--')\n",
    "    axes[1, 0].set_ylim([0, 1])\n",
    "else:\n",
    "    if 'dev_threshold' in history:\n",
    "        axes[1, 0].plot(epochs, history['dev_threshold'], label='Threshold', marker='o', color='green', linewidth=2)\n",
    "        axes[1, 0].set_title('Optimal Threshold (Dev)', fontweight='bold', fontsize=14)\n",
    "        axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "        axes[1, 0].set_ylabel('Threshold', fontsize=12)\n",
    "        axes[1, 0].legend(fontsize=11)\n",
    "        axes[1, 0].grid(alpha=0.3, linestyle='--')\n",
    "        axes[1, 0].set_ylim([0, 1])\n",
    "    else:\n",
    "        axes[1, 0].axis('off')\n",
    "\n",
    "# Learning rate schedule\n",
    "axes[1, 1].plot(epochs, history['learning_rates'], marker='o', color='purple', linewidth=2)\n",
    "axes[1, 1].set_title('Learning Rate Schedule', fontweight='bold', fontsize=14)\n",
    "axes[1, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Learning Rate', fontsize=12)\n",
    "axes[1, 1].set_yscale('log')\n",
    "axes[1, 1].grid(alpha=0.3, linestyle='--', which='both')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'training_curves.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "cm = test_results['confusion_matrix']\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm,\n",
    "            annot=np.array([[f\"{count}\\n({pct:.1%})\" for count, pct in zip(row_counts, row_pcts)] \n",
    "                     for row_counts, row_pcts in zip(cm, cm_normalized)]),\n",
    "    fmt='',\n",
    "    cmap='Blues',\n",
    "    xticklabels=['Oppose (0)', 'Support (1)'],\n",
    "    yticklabels=['Oppose (0)', 'Support (1)'],\n",
    "    ax=ax,\n",
    "    cbar_kws={'label': 'Count'},\n",
    "    linewidths=1,\n",
    "    linecolor='gray'\n",
    ")\n",
    "\n",
    "ax.set_title(\n",
    "    f'Confusion Matrix - Test Set\\n'\n",
    "    f'F1: {test_results[\"f1\"]:.4f} | Acc: {test_results[\"accuracy\"]:.4f} | '\n",
    "    f'P: {test_results[\"precision\"]:.4f} | R: {test_results[\"recall\"]:.4f}',\n",
    "    fontweight='bold', \n",
    "    fontsize=13,\n",
    "    pad=15\n",
    ")\n",
    "ax.set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'confusion_matrix.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# STATS\n",
    "print(f\"   FINAL RESULTS SUMMARY\")\n",
    "print(f\"Test Accuracy:  {test_results['accuracy']:.4f}\")\n",
    "print(f\"Test Precision: {test_results['precision']:.4f}\")\n",
    "print(f\"Test Recall:    {test_results['recall']:.4f}\")\n",
    "print(f\"Test F1 Score:  {test_results['f1']:.4f}\")\n",
    "print(f\"All visualizations saved to: {OUTPUT_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
