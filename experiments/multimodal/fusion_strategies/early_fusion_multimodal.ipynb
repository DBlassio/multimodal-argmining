{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a84cff6",
   "metadata": {},
   "source": [
    "###  Early Fusion Strategies (ResNet50 + DeBERTa)\n",
    "\n",
    "This notebook finds the best early fusion strategy technique:\n",
    "\n",
    "- concat (Our baseline)\n",
    "- mean\n",
    "- avg_pool\n",
    "- weighted_sum\n",
    "- gated\n",
    "- proj_concat\n",
    "\n",
    "We use our baseline architecture:\n",
    "  - Text Branch:  DeBERTa\n",
    "  - Image Branch: ResNet50 (Freezed)\n",
    "\n",
    "With:\n",
    "  - Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "276ab224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  42\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score,f1_score, precision_score, recall_score,confusion_matrix, classification_report\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel,get_linear_schedule_with_warmup,AutoModelForSequenceClassification\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Random seed for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Seed:  {SEED}\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1cf6b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train label distribution:\n",
      "\n",
      " Stance: \n",
      " Oppose: 1095\n",
      " Support: 1095\n",
      "\n",
      "\n",
      "  Persuasiveness \n",
      " No: 1548\n",
      " Yes: 642\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>stance</th>\n",
       "      <th>persuasiveness</th>\n",
       "      <th>split</th>\n",
       "      <th>label</th>\n",
       "      <th>persuasiveness_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1148501065308004357</td>\n",
       "      <td>https://t.co/VQP1FHaWAg</td>\n",
       "      <td>Let's McGyver some Sanity in America!\\n\\nYou a...</td>\n",
       "      <td>support</td>\n",
       "      <td>no</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1103872992537276417</td>\n",
       "      <td>https://t.co/zsyXYSeBkp</td>\n",
       "      <td>A child deserves a chance at life. A child des...</td>\n",
       "      <td>oppose</td>\n",
       "      <td>no</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1151528583623585794_aug</td>\n",
       "      <td>https://t.co/qSWvDX5MnM</td>\n",
       "      <td>Dear prolifers: girls as young as 10, 11, 12 a...</td>\n",
       "      <td>support</td>\n",
       "      <td>no</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1100166844026109953</td>\n",
       "      <td>https://t.co/hxH8tFIHUu</td>\n",
       "      <td>The many States will attempt to amend their co...</td>\n",
       "      <td>support</td>\n",
       "      <td>no</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1021830413550067713</td>\n",
       "      <td>https://t.co/5whvEEtoQR</td>\n",
       "      <td>Every #abortion is wrong, no matter what metho...</td>\n",
       "      <td>oppose</td>\n",
       "      <td>yes</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  tweet_id                tweet_url  \\\n",
       "0      1148501065308004357  https://t.co/VQP1FHaWAg   \n",
       "1      1103872992537276417  https://t.co/zsyXYSeBkp   \n",
       "2  1151528583623585794_aug  https://t.co/qSWvDX5MnM   \n",
       "3      1100166844026109953  https://t.co/hxH8tFIHUu   \n",
       "4      1021830413550067713  https://t.co/5whvEEtoQR   \n",
       "\n",
       "                                          tweet_text   stance persuasiveness  \\\n",
       "0  Let's McGyver some Sanity in America!\\n\\nYou a...  support             no   \n",
       "1  A child deserves a chance at life. A child des...   oppose             no   \n",
       "2  Dear prolifers: girls as young as 10, 11, 12 a...  support             no   \n",
       "3  The many States will attempt to amend their co...  support             no   \n",
       "4  Every #abortion is wrong, no matter what metho...   oppose            yes   \n",
       "\n",
       "   split  label  persuasiveness_label  \n",
       "0  train      1                     0  \n",
       "1  train      0                     0  \n",
       "2  train      1                     0  \n",
       "3  train      1                     0  \n",
       "4  train      0                     1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Paths\n",
    "DATA_PATH = \"../../data/\"\n",
    "IMG_PATH = \"../../data/images\"\n",
    "OUTPUT_DIR = \"../../results/multimodal/baseline_multimodal/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "train_path = os.path.join(DATA_PATH,\"train_augmented.csv\")\n",
    "dev_path   = os.path.join(DATA_PATH,\"dev.csv\")\n",
    "test_path  = os.path.join(DATA_PATH,\"test.csv\")\n",
    "\n",
    "#Load Data\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_dev   = pd.read_csv(dev_path)\n",
    "df_test  = pd.read_csv(test_path)\n",
    "\n",
    "# Map labels to ints\n",
    "stance_2id = {\"oppose\": 0, \"support\": 1}\n",
    "pers_2id = {\"no\": 0, \"yes\": 1}\n",
    "\n",
    "for df in [df_train, df_dev, df_test]:\n",
    "    df[\"label\"] = df[\"stance\"].map(stance_2id)\n",
    "    df[\"persuasiveness_label\"] = df[\"persuasiveness\"].map(pers_2id)\n",
    "\n",
    "\n",
    "print(f\"\\n Train label distribution:\")\n",
    "print(f\"\\n Stance: \\n Oppose: {(df_train['label']==0).sum()}\\n Support: {(df_train['label']==1).sum()}\")\n",
    "print(f\"\\n\\n  Persuasiveness \\n No: {(df_train['persuasiveness_label']==0).sum()}\\n Yes: {(df_train['persuasiveness_label']==1).sum()}\")\n",
    "\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5c180ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models\n",
    "TEXT_MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
    "VISION_MODEL_NAME = \"resnet50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c1a98a3-a727-4f06-8501-dcfad8ee334f",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Training hyperparameters\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 15\n",
    "LEARNING_RATE = 2e-5\n",
    "WEIGHT_DECAY = 1e-4\n",
    "WARMUP_RATIO = 0.1\n",
    "\n",
    "# Early stopping\n",
    "PATIENCE = 5\n",
    "\n",
    "# Image preprocessing\n",
    "IMG_SIZE = 224\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Text preprocessing\n",
    "MAX_TEXT_LENGTH = 105\n",
    "\n",
    "# Other\n",
    "NUM_WORKERS = 1\n",
    "PIN_MEMORY = True if torch.cuda.is_available() else False\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdb7101",
   "metadata": {},
   "source": [
    "###  Multimodal Dataset\n",
    "We create a MultimodalDataset that will return:\n",
    "- tokenized text (input_ids, attention_mask)\n",
    "- image tensor (transforms applied)\n",
    "- label (stance)\n",
    "\n",
    "We will handle corrupted images safely (blank image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98beadeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMG_MEAN, std=IMG_STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ab2f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset that returns (image, text, label) for multimodal learning.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dataframe: pd.DataFrame,\n",
    "        img_dir: str,\n",
    "        tokenizer,\n",
    "        image_transform,\n",
    "        max_length: int = 128\n",
    "    ):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.tokenizer = tokenizer\n",
    "        self.image_transform = image_transform\n",
    "        self.max_length = max_length\n",
    "        \n",
    "\n",
    "        # We calculate class distribution\n",
    "        self.class_counts = self.df['label'].value_counts().to_dict()\n",
    "        self.num_samples = len(self.df)\n",
    "\n",
    "        print(f\"  Dataset created: {self.num_samples} samples\")\n",
    "        print(f\"    - Class 0 (oppose):  {self.class_counts.get(0, 0)} samples\")\n",
    "        print(f\"    - Class 1 (support): {self.class_counts.get(1, 0)} samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # Load Image\n",
    "        img_path = os.path.join(self.img_dir, str(row['tweet_id']) + \".jpg\")\n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            image = self.image_transform(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: could not load image {img_path}. Using grey image instead.\")\n",
    "            image = Image.new(\"RGB\", (224, 224), color=(128, 128, 128))\n",
    "            image = self.image_transform(image)\n",
    "        \n",
    "        # Load Text and Tokenize \n",
    "        text = str(row['tweet_text'])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Our Label\n",
    "        label = row['label']\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(label, dtype=torch.long),\n",
    "            'tweet_id': str(row['tweet_id']),\n",
    "            'text': text\n",
    "        }\n",
    "    \n",
    "    #Attribute to calculate class weights\n",
    "    def get_class_weights(self, device):\n",
    "        num_class_0 = self.class_counts.get(0, 0)\n",
    "        num_class_1 = self.class_counts.get(1, 0)\n",
    "        total = self.num_samples\n",
    "        \n",
    "        weights = torch.tensor([\n",
    "            total / num_class_0 if num_class_0 > 0 else 1.0,\n",
    "            total / num_class_1 if num_class_1 > 0 else 1.0], dtype=torch.float32).to(device)\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acc0de10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded: microsoft/deberta-v3-base\n"
     ]
    }
   ],
   "source": [
    "# Load Tokenized\n",
    "tokenizer = AutoTokenizer.from_pretrained(TEXT_MODEL_NAME)\n",
    "print(f\"Tokenizer loaded: {TEXT_MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82312c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dataset created: 2190 samples\n",
      "    - Class 0 (oppose):  1095 samples\n",
      "    - Class 1 (support): 1095 samples\n",
      "  Dataset created: 200 samples\n",
      "    - Class 0 (oppose):  127 samples\n",
      "    - Class 1 (support): 73 samples\n",
      "  Dataset created: 300 samples\n",
      "    - Class 0 (oppose):  182 samples\n",
      "    - Class 1 (support): 118 samples\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_dataset = MultimodalDataset(df_train, IMG_PATH, tokenizer, image_transforms, MAX_TEXT_LENGTH)\n",
    "dev_dataset = MultimodalDataset(df_dev, IMG_PATH, tokenizer, image_transforms, MAX_TEXT_LENGTH)\n",
    "test_dataset = MultimodalDataset(df_test, IMG_PATH, tokenizer, image_transforms, MAX_TEXT_LENGTH)\n",
    "\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=NUM_WORKERS,pin_memory=True)\n",
    "dev_loader = DataLoader(dev_dataset,batch_size=BATCH_SIZE,shuffle=False,num_workers=NUM_WORKERS,pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=False,num_workers=NUM_WORKERS,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfe4a5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Image shape: torch.Size([3, 224, 224])\n",
      "  Input IDs shape: torch.Size([105])\n",
      "  Label: 1\n",
      "  Text (truncated): Let's McGyver some Sanity in America!\n",
      "\n",
      "You are not pro-life if you lock children in cages, deny them lunch at school, or cut programs for the disabled!\n",
      "\n",
      "And, good Christians don't applaud rapists, con men, &amp; hate!\n",
      "\n",
      "Hate Fixes NADDA! It just creates more problems!\n",
      "\n",
      "ðŸ§°ðŸ“ðŸ”Žâ›ï¸ðŸ”§ðŸ› ï¸ðŸ§° https://t.co/VQP1FHaWAg\n"
     ]
    }
   ],
   "source": [
    "#We test our datasets and loaders\n",
    "sample = train_dataset[0]\n",
    "print(f\"  Image shape: {sample['image'].shape}\")\n",
    "print(f\"  Input IDs shape: {sample['input_ids'].shape}\")\n",
    "print(f\"  Label: {sample['label'].item()}\")\n",
    "print(f\"  Text (truncated): {sample['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c69a3148",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mMultimodalBaseline\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m      4\u001b[0m         text_model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/deberta-v3-base\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m         freeze_vision\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      9\u001b[0m         fusion_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconcat\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class MultimodalBaseline(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        text_model_name=\"microsoft/deberta-v3-base\",\n",
    "        vision_model_name=\"resnet50\",\n",
    "        num_classes=2,\n",
    "        freeze_text=False,\n",
    "        freeze_vision=True,\n",
    "        fusion_type=\"concat\"):\n",
    "        super().__init__()\n",
    "\n",
    "        assert fusion_type in [\"concat\",\"mean\",\"avg_pool\",\"weighted_sum\",\"gated\",\"proj_concat\"]\n",
    "        self.fusion_type = fusion_type\n",
    "\n",
    "        # TEXT ENCODER\n",
    "        print(f\"Loading TEXT encoder: {text_model_name}\")\n",
    "        self.text_encoder = AutoModel.from_pretrained(text_model_name)\n",
    "        self.text_hidden = self.text_encoder.config.hidden_size\n",
    "\n",
    "        if freeze_text:\n",
    "            for p in self.text_encoder.parameters():\n",
    "                p.requires_grad = False\n",
    "            print(\"Text encoder FROZEN\")\n",
    "\n",
    "        # VISION ENCODER\n",
    "        print(f\"Loading VISION encoder: {vision_model_name}\")\n",
    "        vision_model = models.resnet50(pretrained=True)\n",
    "        self.vision_encoder = nn.Sequential(*list(vision_model.children())[:-1])\n",
    "        self.vision_hidden = 2048\n",
    "\n",
    "        if freeze_vision:\n",
    "            for p in self.vision_encoder.parameters():\n",
    "                p.requires_grad = False\n",
    "            print(\"Vision encoder FROZEN\")\n",
    "\n",
    "        # Project vision to text space\n",
    "        self.vision_proj = nn.Linear(self.vision_hidden, self.text_hidden)\n",
    "\n",
    "        # FUSION-SPECIFIC MODULES\n",
    "        if fusion_type == \"weighted_sum\":\n",
    "            self.alpha = nn.Parameter(torch.tensor(0.5))\n",
    "\n",
    "        elif fusion_type == \"gated\":\n",
    "            self.gate = nn.Sequential(\n",
    "                nn.Linear(self.text_hidden * 2, self.text_hidden),\n",
    "                nn.Sigmoid())\n",
    "\n",
    "        elif fusion_type == \"proj_concat\":\n",
    "            self.text_proj = nn.Linear(self.text_hidden, self.text_hidden)\n",
    "            self.vision_proj2 = nn.Linear(self.text_hidden, self.text_hidden)\n",
    "\n",
    "        # CLASSIFIER\n",
    "        if fusion_type in [\"concat\", \"proj_concat\"]:\n",
    "            classifier_in = self.text_hidden * 2\n",
    "        else:\n",
    "            classifier_in = self.text_hidden\n",
    "\n",
    "        self.classifier = nn.Linear(classifier_in, num_classes)\n",
    "\n",
    "        print(f\"Multimodal baseline initialized | Fusion = {fusion_type}\")\n",
    "\n",
    "    # FORWARD\n",
    "    def forward(self, input_ids, attention_mask, images=None, mode=\"multimodal\"):\n",
    "\n",
    "        # TEXT\n",
    "        text_out = self.text_encoder(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        text_emb = text_out.last_hidden_state[:, 0, :]  # CLS\n",
    "\n",
    "        # VISION\n",
    "        if mode == \"multimodal\" and images is not None:\n",
    "            vision_feat = self.vision_encoder(images)\n",
    "            vision_feat = vision_feat.squeeze(-1).squeeze(-1)\n",
    "            vision_emb = self.vision_proj(vision_feat)\n",
    "        else:\n",
    "            vision_emb = torch.zeros_like(text_emb)\n",
    "\n",
    "        # EARLY FUSION\n",
    "        if self.fusion_type == \"concat\":\n",
    "            fused = torch.cat([text_emb, vision_emb], dim=1)\n",
    "\n",
    "        elif self.fusion_type == \"mean\":\n",
    "            fused = (text_emb + vision_emb) / 2\n",
    "\n",
    "        elif self.fusion_type == \"avg_pool\":\n",
    "            fused = torch.stack([text_emb, vision_emb], dim=1).mean(dim=1)\n",
    "\n",
    "        elif self.fusion_type == \"weighted_sum\":\n",
    "            alpha = torch.sigmoid(self.alpha)\n",
    "            fused = alpha * text_emb + (1 - alpha) * vision_emb\n",
    "\n",
    "        elif self.fusion_type == \"gated\":\n",
    "            gate = self.gate(torch.cat([text_emb, vision_emb], dim=1))\n",
    "            fused = gate * text_emb + (1 - gate) * vision_emb\n",
    "\n",
    "        elif self.fusion_type == \"proj_concat\":\n",
    "            t = self.text_proj(text_emb)\n",
    "            v = self.vision_proj2(vision_emb)\n",
    "            fused = torch.cat([t, v], dim=1)\n",
    "\n",
    "        # CLASSIFIER\n",
    "        logits = self.classifier(fused)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a2c009-0159-4dd9-bea5-56edcd35a2c8",
   "metadata": {},
   "source": [
    "#### Sanity Check (Forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd249f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TEXT encoder: microsoft/deberta-v3-base\n",
      "Loading VISION encoder: resnet50\n",
      "Vision encoder FROZEN\n",
      "Multimodal baseline initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Logits shape: torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Forward Pass Shape Check\n",
    "fusion_types = [\"concat\",\"mean\",\"avg_pool\",\"weighted_sum\",\"gated\",\"proj_concat\"]\n",
    "\n",
    "sample_batch = next(iter(train_loader))\n",
    "for fusion in fusion_types:\n",
    "    print(f\"\\nTesting fusion: {fusion}\")\n",
    "\n",
    "    model = MultimodalBaseline(\n",
    "        text_model_name=TEXT_MODEL_NAME,\n",
    "        num_classes=2,\n",
    "        freeze_text=False,\n",
    "        freeze_vision=True,\n",
    "        fusion_type=fusion).to(DEVICE)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(\n",
    "            input_ids=sample_batch[\"input_ids\"][:2].to(DEVICE),\n",
    "            attention_mask=sample_batch[\"attention_mask\"][:2].to(DEVICE),\n",
    "            images=sample_batch[\"image\"][:2].to(DEVICE),\n",
    "            mode=\"multimodal\")\n",
    "\n",
    "    print(\"Logits shape:\", logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226a7edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vision Influence Check\n",
    "def vision_influence_check(model, batch, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits_with_img = model(\n",
    "            input_ids=batch[\"input_ids\"][:2].to(device),\n",
    "            attention_mask=batch[\"attention_mask\"][:2].to(device),\n",
    "            images=batch[\"image\"][:2].to(device),\n",
    "            mode=\"multimodal\"\n",
    "        )\n",
    "\n",
    "        logits_no_img = model(\n",
    "            input_ids=batch[\"input_ids\"][:2].to(device),\n",
    "            attention_mask=batch[\"attention_mask\"][:2].to(device),\n",
    "            images=None,\n",
    "            mode=\"multimodal\"\n",
    "        )\n",
    "\n",
    "    delta = (logits_with_img - logits_no_img).abs().mean().item()\n",
    "    return delta\n",
    "\n",
    "for fusion in fusion_types:\n",
    "    model = MultimodalBaseline(\n",
    "        text_model_name=TEXT_MODEL_NAME,\n",
    "        num_classes=2,\n",
    "        freeze_text=False,\n",
    "        freeze_vision=True,\n",
    "        fusion_type=fusion).to(DEVICE)\n",
    "\n",
    "    delta = vision_influence_check(model, sample_batch, DEVICE)\n",
    "    print(f\"Fusion={fusion:12s} | diff logits (mean abs): {delta:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b48d97",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81476ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multimodal_model(\n",
    "    model, \n",
    "    train_loader, \n",
    "    dev_loader,\n",
    "    num_epochs=15, \n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=1e-4, \n",
    "    warmup_ratio=0.1,\n",
    "    mode=\"multimodal\",\n",
    "    patience=5, \n",
    "    device=DEVICE):\n",
    "    \n",
    "    model = model.to(device)\n",
    "    print(f\"Fusion strategy: {model.fusion_type}\")\n",
    "\n",
    "\n",
    "    # Class Weights (If data unblanced)\n",
    "    class_weights = train_loader.dataset.get_class_weights(device)\n",
    "    print(f\"Class weights: oppose={class_weights[0]:.3f}, support={class_weights[1]:.3f}\")\n",
    "\n",
    "    # Loss\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "\n",
    "    # Scheduler \n",
    "    num_training_steps = len(train_loader) * num_epochs\n",
    "    num_warmup_steps = int(num_training_steps * warmup_ratio)\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=num_warmup_steps,num_training_steps=num_training_steps)\n",
    "    print(f\"Total training steps: {num_training_steps}\")\n",
    "    print(f\"Warmup steps: {num_warmup_steps}\")\n",
    "\n",
    "    #  History \n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_f1\": [],\n",
    "        \"dev_loss\": [],\n",
    "        \"dev_f1\": [],\n",
    "        \"learning_rates\": []\n",
    "    }\n",
    "\n",
    "    #  Early stopping \n",
    "    best_f1 = 0.0\n",
    "    best_model_state = None\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    # OUR TRAINING LOOP\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_preds = []\n",
    "        train_labels = []\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            images = batch[\"image\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            logits = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                images=images,\n",
    "                mode=mode)\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            train_loss += loss.item() * labels.size(0)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_f1 = f1_score(train_labels, train_preds, average=\"binary\", pos_label=1)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        dev_loss = 0.0\n",
    "        dev_preds = []\n",
    "        dev_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dev_loader, desc=\"Validation\", leave=False):\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                images = batch[\"image\"].to(device)\n",
    "                labels = batch[\"label\"].to(device)\n",
    "\n",
    "                logits = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    images=images,\n",
    "                    mode=mode)\n",
    "\n",
    "                loss = criterion(logits, labels)\n",
    "                dev_loss += loss.item() * labels.size(0)\n",
    "\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                dev_preds.extend(preds.cpu().numpy())\n",
    "                dev_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        dev_loss /= len(dev_loader.dataset)\n",
    "        dev_f1 = f1_score(dev_labels, dev_preds, average=\"binary\", pos_label=1)\n",
    "\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_f1\"].append(train_f1)\n",
    "        history[\"dev_loss\"].append(dev_loss)\n",
    "        history[\"dev_f1\"].append(dev_f1)\n",
    "        history[\"learning_rates\"].append(current_lr)\n",
    "\n",
    "        print(f\"TRAIN LOSS: {train_loss:.4f} | F1: {train_f1:.4f}\")\n",
    "        print(f\"DEV LOSS: {dev_loss:.4f} | F1: {dev_f1:.4f}\")\n",
    "        print(f\"LR: {current_lr:.2e}\")\n",
    "\n",
    "        # Early Stopping\n",
    "        if dev_f1 > best_f1:\n",
    "            best_f1 = dev_f1\n",
    "            best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            epochs_without_improvement = 0\n",
    "            print(f\"  New best Dev F1: {best_f1:.4f}\")\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            print(f\"No improvement for {epochs_without_improvement} epoch(s)\")\n",
    "\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(\"\\n  Early stopping triggered!\")\n",
    "                break\n",
    "\n",
    "    # Load Best Model\n",
    "    model.load_state_dict(best_model_state)\n",
    "    model = model.to(device)\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training complete!\")\n",
    "    print(f\"Best Dev F1 (pos=1): {best_f1:.4f}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e7b4cd",
   "metadata": {},
   "source": [
    "### Evaluation (Test Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a188dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,dataloader,threshold=0.5,mode=\"multimodal\",device=\"cuda\",verbose=True):\n",
    "    \n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\", disable=not verbose):\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            images = batch[\"image\"].to(device)\n",
    "\n",
    "\n",
    "            #Text Only\n",
    "            if mode==\"text_only\":\n",
    "                logits = model(input_ids=input_ids,\n",
    "                               attention_mask=attention_mask,\n",
    "                               images=None,\n",
    "                               mode=mode)\n",
    "                \n",
    "            #Multimodal\n",
    "            else:\n",
    "                logits = model(input_ids=input_ids,\n",
    "                           attention_mask=attention_mask,\n",
    "                           images=images,\n",
    "                           mode=mode)\n",
    "\n",
    "            probs = torch.softmax(logits, dim=1)[:, 1]\n",
    "            preds = (probs >= threshold).long()\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Convert to numpy\n",
    "    y_true = np.array(all_labels)\n",
    "    y_pred = np.array(all_preds)\n",
    "    y_prob = np.array(all_probs)\n",
    "\n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average=\"binary\", pos_label=1)\n",
    "    precision = precision_score(y_true, y_pred, average=\"binary\", pos_label=1, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average=\"binary\", pos_label=1)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': cm,\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred,\n",
    "        'y_prob': y_prob,\n",
    "        'threshold': threshold\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94caf65",
   "metadata": {},
   "source": [
    "### RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9647e92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MULTIMODAL MODEL\n",
      "Loading TEXT encoder: microsoft/deberta-v3-base\n",
      "Loading VISION encoder: resnet50\n",
      "Vision encoder FROZEN\n",
      "Multimodal baseline initialized.\n",
      "Class weights: oppose=2.000, support=2.000\n",
      "Total training steps: 2055\n",
      "Warmup steps: 205\n",
      "\n",
      "============================================================\n",
      "Epoch 1/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218d91a15e7e4b069ecac64111231894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN LOSS: 0.6208 | F1: 0.5400\n",
      "DEV LOSS: 0.4754 | F1: 0.7097\n",
      "LR: 1.34e-05\n",
      "  New best Dev F1: 0.7097\n",
      "\n",
      "============================================================\n",
      "Epoch 2/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9058429791ad4bd7a1787c3e4d053672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN LOSS: 0.2908 | F1: 0.8723\n",
      "DEV LOSS: 0.2497 | F1: 0.8657\n",
      "LR: 1.93e-05\n",
      "  New best Dev F1: 0.8657\n",
      "\n",
      "============================================================\n",
      "Epoch 3/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c576024071774a408a56e3600794cc57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN LOSS: 0.1210 | F1: 0.9546\n",
      "DEV LOSS: 0.3720 | F1: 0.8841\n",
      "LR: 1.78e-05\n",
      "  New best Dev F1: 0.8841\n",
      "\n",
      "============================================================\n",
      "Epoch 4/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77f1f99ccfd431e830e15dd1d55372e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN LOSS: 0.0561 | F1: 0.9835\n",
      "DEV LOSS: 0.4371 | F1: 0.8652\n",
      "LR: 1.63e-05\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "============================================================\n",
      "Epoch 5/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bcb621357924aa6a723c34ee94ff274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN LOSS: 0.0315 | F1: 0.9922\n",
      "DEV LOSS: 0.4196 | F1: 0.9028\n",
      "LR: 1.48e-05\n",
      "  New best Dev F1: 0.9028\n",
      "\n",
      "============================================================\n",
      "Epoch 6/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9359db71fb4647f7804cdc001d63cabf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN LOSS: 0.0203 | F1: 0.9931\n",
      "DEV LOSS: 0.4234 | F1: 0.9000\n",
      "LR: 1.33e-05\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "============================================================\n",
      "Epoch 7/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc2b24459614174964a484a5fdbefae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466a0f5445064f61be2971363332ba0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN LOSS: 0.0096 | F1: 0.9982\n",
      "DEV LOSS: 0.4040 | F1: 0.9014\n",
      "LR: 1.18e-05\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "============================================================\n",
      "Epoch 8/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb06371b4a514d8896a2fad6867f9e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025c16e115414c99a26022e0869e96e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN LOSS: 0.0130 | F1: 0.9959\n",
      "DEV LOSS: 0.4610 | F1: 0.9118\n",
      "LR: 1.04e-05\n",
      "  New best Dev F1: 0.9118\n",
      "\n",
      "============================================================\n",
      "Epoch 9/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7be0f3a23d94f5da7dc0834235ffd04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6707875d63046bab211409949dd99c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN LOSS: 0.0072 | F1: 0.9986\n",
      "DEV LOSS: 0.4223 | F1: 0.9078\n",
      "LR: 8.89e-06\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "============================================================\n",
      "Epoch 10/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9321512a08d94ec286cac2cd891d3f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33bfe46c1174bd0bc24ae354759dd11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN LOSS: 0.0045 | F1: 0.9986\n",
      "DEV LOSS: 0.4650 | F1: 0.9078\n",
      "LR: 7.41e-06\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "============================================================\n",
      "Epoch 11/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7737b68af2f749359b8bb18f5dc8193f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946efe88d78b4d40a675c7fb772f11be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN LOSS: 0.0052 | F1: 0.9982\n",
      "DEV LOSS: 0.4801 | F1: 0.9078\n",
      "LR: 5.92e-06\n",
      "No improvement for 3 epoch(s)\n",
      "\n",
      "============================================================\n",
      "Epoch 12/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de153f0aa773441eae8b709f3b4e6dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bccf48933ba4f909af3f9033dc203e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN LOSS: 0.0031 | F1: 0.9986\n",
      "DEV LOSS: 0.5099 | F1: 0.9078\n",
      "LR: 4.44e-06\n",
      "No improvement for 4 epoch(s)\n",
      "\n",
      "============================================================\n",
      "Epoch 13/15\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7cbbc5dee854c009dbdb81618742f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1163936804006977536.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1366231979495153664.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1290280312962940928.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370197831223447552.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1339326387556151315.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1348716022673629187.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1375886605555097603.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1346943760177852420.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1358026995301498883.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1364638614240583680.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1324601823555104768.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1354941521422905347.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1200177857869336576.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1323378473663188994.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1370338056415289348.jpg. Using grey image instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fbbff4e9870>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dzuniga/.conda/envs/multimodal/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not load image ../../data/images/1349706761033420801.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1347578011751763968.jpg. Using grey image instead.\n",
      "Warning: could not load image ../../data/images/1374785380164190214.jpg. Using grey image instead.\n",
      "TRAIN LOSS: 0.0014 | F1: 0.9995\n",
      "DEV LOSS: 0.5426 | F1: 0.8806\n",
      "LR: 2.96e-06\n",
      "No improvement for 5 epoch(s)\n",
      "\n",
      "  Early stopping triggered!\n",
      "\n",
      "============================================================\n",
      "Training complete!\n",
      "Best Dev F1 (pos=1): 0.9118\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Training and evaluating multimodal models with different fusion strategies.\")\n",
    "results = {}\n",
    "\n",
    "for fusion in fusion_types:\n",
    "    print(f\"    Running experiment: {fusion}\")\n",
    "    \n",
    "    # We initialize the model with the chosen fusion\n",
    "    model = MultimodalBaseline(\n",
    "        text_model_name=TEXT_MODEL_NAME,\n",
    "        num_classes=2,\n",
    "        freeze_text=False,\n",
    "        freeze_vision=True,\n",
    "        fusion_type=fusion).to(DEVICE)\n",
    "\n",
    "    # Training loop\n",
    "    model, history = train_multimodal_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        dev_loader=dev_loader,\n",
    "        num_epochs=NUM_EPOCHS,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        warmup_ratio=WARMUP_RATIO,\n",
    "        mode=\"multimodal\",\n",
    "        patience=PATIENCE,\n",
    "        device=DEVICE)\n",
    "\n",
    "    # Evaluation on Test Set\n",
    "    test_results = evaluate_model(\n",
    "        model=model,\n",
    "        dataloader=test_loader,\n",
    "        threshold=0.5,\n",
    "        mode=\"multimodal\",\n",
    "        device=DEVICE,\n",
    "        verbose=False)\n",
    "\n",
    "    # Results\n",
    "    results[fusion] = {\n",
    "        \"best_dev_f1\": max(history[\"dev_f1\"]),\n",
    "        \"test_f1\": test_results[\"f1\"],\n",
    "        \"test_precision\": test_results[\"precision\"],\n",
    "        \"test_recall\": test_results[\"recall\"],\n",
    "        \"test_accuracy\": test_results[\"accuracy\"]\n",
    "    }\n",
    "\n",
    "# Final Summary\n",
    "print(\"\\nSummary of all fusion strategies on Test Set:\")\n",
    "for fusion, metrics in results.items():\n",
    "    print(f\"Fusion: {fusion:12s} | Dev F1: {metrics['best_dev_f1']:.4f} | \"\n",
    "          f\"Test F1: {metrics['test_f1']:.4f} | Precision: {metrics['test_precision']:.4f} | \"\n",
    "          f\"Recall: {metrics['test_recall']:.4f} | Accuracy: {metrics['test_accuracy']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
