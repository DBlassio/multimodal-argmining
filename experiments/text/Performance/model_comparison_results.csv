Model,Accuracy_Mean,Accuracy_Std,Precision_Mean,Precision_Std,Recall_Mean,Recall_Std,F1_Mean,F1_Std
microsoft/deberta-v3-base,0.8467,0.02,0.8549,0.0148,0.8467,0.02,0.8434,0.0219
roberta-base,0.8244,0.0038,0.8265,0.0041,0.8244,0.0038,0.8223,0.0039
microsoft/deberta-base,0.8222,0.0038,0.8347,0.0022,0.8222,0.0038,0.817,0.005
cardiffnlp/twitter-roberta-base,0.82,0.0115,0.8275,0.0142,0.82,0.0115,0.8161,0.0115
bert-base-uncased,0.8022,0.0139,0.8039,0.0157,0.8022,0.0139,0.7998,0.0135
ddore14/RooseBERT-scr-uncased,0.7956,0.0102,0.8077,0.0101,0.7956,0.0102,0.7889,0.0109
