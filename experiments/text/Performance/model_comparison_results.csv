Model,Accuracy_Mean,Accuracy_Std,Precision_Mean,Precision_Std,Recall_Mean,Recall_Std,F1_Mean,F1_Std
roberta-base,0.85,0.0033,0.8448,0.0038,0.86,0.0042,0.8471,0.0035
vinai/bertweet-base,0.8311,0.0117,0.8262,0.0107,0.8404,0.0104,0.8279,0.0115
microsoft/deberta-v3-base,0.82,0.0219,0.8266,0.0143,0.8407,0.0167,0.8187,0.0212
cardiffnlp/twitter-roberta-base,0.8167,0.0115,0.8174,0.0066,0.8315,0.006,0.8144,0.0104
bert-base-uncased,0.8133,0.0115,0.809,0.0052,0.8208,0.0038,0.8094,0.0097
microsoft/deberta-base,0.81,0.0219,0.8109,0.0161,0.825,0.0169,0.8078,0.021
