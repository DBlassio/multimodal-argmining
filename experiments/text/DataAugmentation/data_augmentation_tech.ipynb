{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "70dcfe4b",
      "metadata": {
        "id": "70dcfe4b",
        "outputId": "c9293831-9aa6-46a1-ddbf-7f7d04698fca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Loading data from Google Drive: /content/drive/MyDrive/multimodal-argmining\n",
            "No GPU detecting, using CPU.\n"
          ]
        }
      ],
      "source": [
        "#Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from datasets import Dataset\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nlpaug.augmenter.word as naw\n",
        "from googletrans import Translator\n",
        "import random, time\n",
        "import sentencepiece\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, T5Tokenizer, Trainer, TrainingArguments, EarlyStoppingCallback, AutoModelForSequenceClassification\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# Google Colab or not\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    path = \"/content/drive/MyDrive/multimodal-argmining\"\n",
        "    os.chdir(path)\n",
        "    print(f\"Loading data from Google Drive: {path}\")\n",
        "else:\n",
        "    path = \"C:/Users/diego/Desktop/Master Neuro/M2/Intership_NLP/multimodal-argmining\"\n",
        "    os.chdir(path)\n",
        "    print(f\"Loading data locally from: {path}\")\n",
        "\n",
        "\n",
        "# GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU ready:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"No GPU detecting, using CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"Esto es un prueba\""
      ],
      "metadata": {
        "id": "yp8IFOGn0ZbH",
        "outputId": "d1351382-d111-467b-ac88-7607a2cdccf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "yp8IFOGn0ZbH",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Esto es un prueba'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fc7c796",
      "metadata": {
        "id": "5fc7c796"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"roberta-base\"  # wE CAn change this to any model you want to use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a9ffdac",
      "metadata": {
        "id": "0a9ffdac"
      },
      "outputs": [],
      "source": [
        "#Load Dataset\n",
        "train_path = f\"{path}/data/train.csv\"\n",
        "dev_path   = f\"{path}/data/dev.csv\"\n",
        "test_path  = f\"{path}/data/test.csv\"\n",
        "\n",
        "df_train = pd.read_csv(train_path)\n",
        "df_dev   = pd.read_csv(dev_path)\n",
        "df_test  = pd.read_csv(test_path)\n",
        "\n",
        "\n",
        "# Map labels to ints\n",
        "label2id = {\"oppose\": 0, \"support\": 1}\n",
        "for df in [df_train, df_dev, df_test]:\n",
        "    df[\"label\"] = df[\"stance\"].map(label2id)\n",
        "\n",
        "df_train.head()\n",
        "\n",
        "\n",
        "dataset_train = Dataset.from_pandas(df_train[[\"tweet_text\", \"label\"]])\n",
        "dataset_dev   = Dataset.from_pandas(df_dev[[\"tweet_text\", \"label\"]])\n",
        "dataset_test  = Dataset.from_pandas(df_test[[\"tweet_text\", \"label\"]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0122bfb2",
      "metadata": {
        "id": "0122bfb2"
      },
      "outputs": [],
      "source": [
        "print(\"Train class distribution:\")\n",
        "stance_counts = df_train['stance'].value_counts()\n",
        "print(\"Stance value counts:\\n\", stance_counts)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.barplot(x=stance_counts.index, y=stance_counts.values, palette=\"viridis\")\n",
        "plt.title(\"Stance Distribution - Train Set \")\n",
        "plt.ylabel(\"Number of Tweets\")\n",
        "plt.xlabel(\"Stance\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea55ef6e",
      "metadata": {
        "id": "ea55ef6e"
      },
      "source": [
        "## Data Augmentation Techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "810c85c9",
      "metadata": {
        "id": "810c85c9"
      },
      "source": [
        "### Synonym Replacement (WordNet)\n",
        "\n",
        "This technique randomly selects words in a sentence (excluding stop words) and replaces them with synonyms obtained from a lexical database like WordNet. The goal is to create semantically similar sentences without changing the meaning.  \n",
        "\n",
        "**Example:**  \n",
        "Original: \"Gun control laws should be stricter to reduce crime.\"  \n",
        "Augmented: \"Firearm regulation rules should be tougher to reduce crime.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db9e9b23",
      "metadata": {
        "id": "db9e9b23"
      },
      "outputs": [],
      "source": [
        "def augment_synonym(texts, n=1):\n",
        "    aug = naw.SynonymAug(aug_p=0.2) #aug_p = probability of words to be augmented.\n",
        "    augmented = [aug.augment(t) for t in texts for _ in range(n)]\n",
        "    return augmented"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e28d9bd7",
      "metadata": {
        "id": "e28d9bd7"
      },
      "source": [
        "### Back Translation\n",
        "\n",
        "Back translation involves translating a sentence to another language and then translating it back to the original language. This introduces natural paraphrases and linguistic variations.  \n",
        "\n",
        "**Example:**  \n",
        "Original: \"We need stronger gun regulations.\"  \n",
        "Augmented: \"It is necessary to have stricter firearm laws.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "851f0b0a",
      "metadata": {
        "id": "851f0b0a"
      },
      "outputs": [],
      "source": [
        "def back_translate(texts, n=1, sleep_time=0.3):\n",
        "    translator = Translator()\n",
        "    augmented = []\n",
        "    for t in texts:\n",
        "        try:\n",
        "            fr = translator.translate(t, src=\"en\", dest=\"fr\").text\n",
        "            back = translator.translate(fr, src=\"fr\", dest=\"en\").text\n",
        "            augmented.append(back)\n",
        "            time.sleep(sleep_time)\n",
        "        except:\n",
        "            continue\n",
        "    return augmented\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb3cba25",
      "metadata": {
        "id": "cb3cba25"
      },
      "source": [
        "### Paraphrasing with T5 / Pegasus\n",
        "\n",
        "Paraphrasing models (like T5 or Pegasus) generate alternative ways of writing a sentence while preserving its meaning. These models are trained on large datasets of paraphrase pairs.  \n",
        "\n",
        "**Example:**  \n",
        "Original: \"The Second Amendment should be reconsidered.\"  \n",
        "Augmented: \"We should rethink the Second Amendment.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02551799",
      "metadata": {
        "id": "02551799"
      },
      "outputs": [],
      "source": [
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\", use_fast=False)\n",
        "para_tokenizer = AutoTokenizer.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")\n",
        "para_model = AutoModelForSeq2SeqLM.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")\n",
        "\n",
        "def augment_paraphrase(texts, n=1):\n",
        "    augmented = []\n",
        "    for t in texts:\n",
        "        input_text = f\"paraphrase: {t} </s>\"\n",
        "        encoding = para_tokenizer.encode_plus(input_text, return_tensors=\"pt\", truncation=True)\n",
        "        outputs = para_model.generate(\n",
        "            **encoding, max_length=128, num_beams=5, num_return_sequences=n\n",
        "        )\n",
        "        for output in outputs:\n",
        "            augmented.append(para_tokenizer.decode(output, skip_special_tokens=True))\n",
        "    return augmented"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f7c805c",
      "metadata": {
        "id": "0f7c805c"
      },
      "source": [
        "### Noise Injection\n",
        "\n",
        "Randomly removes or inserts words in a sentence, introducing small perturbations. This simulates noisy text, such as typos or incomplete sentences.  \n",
        "\n",
        "**Example:**  \n",
        "Original: \"Gun control laws need to be enforced strictly.\"  \n",
        "Augmented: \"Gun laws need enforced strictly.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22f41279",
      "metadata": {
        "id": "22f41279"
      },
      "outputs": [],
      "source": [
        "def augment_noise(texts, del_prob=0.1):\n",
        "    augmented = []\n",
        "    for t in texts:\n",
        "        words = t.split()\n",
        "        new_words = [w for w in words if random.random() > del_prob]\n",
        "        augmented.append(\" \".join(new_words))\n",
        "    return augmented\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8efa5986",
      "metadata": {
        "id": "8efa5986"
      },
      "source": [
        "## Generate our Augmented Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9077cd3",
      "metadata": {
        "id": "b9077cd3"
      },
      "outputs": [],
      "source": [
        "minority_df = df_train[df_train[\"label\"] == 1]\n",
        "n_samples = len(df_train[df_train[\"label\"] == 0]) - len(minority_df)\n",
        "texts_to_augment = minority_df[\"tweet_text\"].tolist()\n",
        "\n",
        "augmentations = {\n",
        "    \"synonym\": augment_synonym,\n",
        "    \"back_translation\": back_translate,\n",
        "    \"paraphrase\": augment_paraphrase,\n",
        "    \"noise\": augment_noise\n",
        "}\n",
        "\n",
        "# Generate our augmented datasets\n",
        "augmented_datasets = {}\n",
        "\n",
        "for name, func in augmentations.items():\n",
        "    print(f\"Generating dataset with technique: {name}...\")\n",
        "\n",
        "    augmented_texts = func(texts_to_augment[:n_samples])\n",
        "    #augmented_texts = augmented_texts[:n_samples]\n",
        "\n",
        "    new_df = pd.concat([\n",
        "        df_train,\n",
        "        pd.DataFrame({\n",
        "            \"tweet_text\": augmented_texts,\n",
        "            \"stance\": \"support\",\n",
        "            \"label\": 1\n",
        "        })\n",
        "    ], ignore_index=True)\n",
        "\n",
        "    augmented_datasets[name] = new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7459ffa3",
      "metadata": {
        "id": "7459ffa3"
      },
      "outputs": [],
      "source": [
        "# Visualize augmented datasets distribution\n",
        "for name, df_aug in augmented_datasets.items():\n",
        "    stance_counts = df_aug['stance'].value_counts()\n",
        "\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.barplot(x=stance_counts.index, y=stance_counts.values, palette=\"viridis\")\n",
        "    plt.title(f\"Stance Distribution - {name.capitalize()} Augmentation\")\n",
        "    plt.ylabel(\"Number of Tweets\")\n",
        "    plt.xlabel(\"Stance\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "101af04e",
      "metadata": {
        "id": "101af04e"
      },
      "outputs": [],
      "source": [
        "#Metrics we are going to evaluate\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, preds),\n",
        "        \"f1\": f1_score(labels, preds, average=\"macro\"),\n",
        "        \"precision\": precision_score(labels, preds, average=\"macro\"),\n",
        "        \"recall\": recall_score(labels, preds, average=\"macro\")\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7c82c38",
      "metadata": {
        "id": "a7c82c38"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Tokenization Function for each model\n",
        "def tokenize_dataset(dataset, tokenizer, max_length=105):\n",
        "\n",
        "    def tokenize_batch(batch):\n",
        "        return tokenizer(batch[\"tweet_text\"],padding=\"max_length\",truncation=True,max_length=max_length)\n",
        "\n",
        "    tokenized = dataset.map(tokenize_batch, batched=True)\n",
        "\n",
        "    tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "    return tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43dc3d53",
      "metadata": {
        "id": "43dc3d53"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate function\n",
        "def train_and_evaluate(model_name, train_dataset, dev_dataset, test_dataset, seed=42, max_len=105):\n",
        "\n",
        "    #Set Seed\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "    # Load tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    print(f\"Tokenizer loaded for {model_name}...\")\n",
        "\n",
        "    # Tokenize datasets with model tokenizer\n",
        "    train_dataset_tok = tokenize_dataset(train_dataset, tokenizer, 105)\n",
        "    dev_dataset_tok = tokenize_dataset(dev_dataset, tokenizer, 105)\n",
        "    test_dataset_tok = tokenize_dataset(test_dataset, tokenizer, 105)\n",
        "    print(f\"Tokenization complete\")\n",
        "\n",
        "    # Load model\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "    print(f\"Model Loaded: {model_name}.\")\n",
        "\n",
        "\n",
        "    # TrainingArguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./temp_models/{model_name.replace('/', '_')}_seed{seed}\",\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"no\",\n",
        "        logging_strategy=\"epoch\",\n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        num_train_epochs=5,\n",
        "        weight_decay=0.01,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1\",\n",
        "        report_to=\"none\",\n",
        "        logging_steps=10\n",
        "    )\n",
        "\n",
        "    # Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset_tok,\n",
        "        eval_dataset=dev_dataset_tok,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    print(f\"\\n Starting training...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # Predictions on TEST set\n",
        "    print(f\"\\n Getting predictions on TEST set...\")\n",
        "    predictions_output = trainer.predict(test_dataset_tok)\n",
        "    y_pred = np.argmax(predictions_output.predictions, axis=1)\n",
        "    y_true = predictions_output.label_ids\n",
        "\n",
        "\n",
        "    # Metrics\n",
        "    metrics = compute_metrics(predictions_output)\n",
        "    metrics[\"y_true\"] = y_true\n",
        "    metrics[\"y_pred\"] = y_pred\n",
        "\n",
        "    print(f\"\\n Results for {model_name}:\")\n",
        "    print(f\"   Accuracy:  {metrics['accuracy']:.4f}\")\n",
        "    print(f\"   Precision: {metrics['precision']:.4f}\")\n",
        "    print(f\"   Recall:    {metrics['recall']:.4f}\")\n",
        "    print(f\"   F1-Score:  {metrics['f1']:.4f}\")\n",
        "\n",
        "    # Cleanup\n",
        "    del model, trainer, train_dataset_tok, dev_dataset_tok, test_dataset_tok\n",
        "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e171904",
      "metadata": {
        "id": "5e171904"
      },
      "outputs": [],
      "source": [
        "results_all = []\n",
        "\n",
        "for technique_name, df_aug in augmented_datasets.items():\n",
        "    print(f\"\\nTraining with augmentation: {technique_name}\")\n",
        "    dataset_aug = Dataset.from_pandas(df_aug[[\"tweet_text\",\"label\"]])\n",
        "\n",
        "    metrics = train_and_evaluate(\n",
        "        model_name=MODEL_NAME,\n",
        "        train_dataset=dataset_aug,\n",
        "        dev_dataset=dataset_dev,\n",
        "        test_dataset=dataset_test,\n",
        "        seed=42\n",
        "    )\n",
        "\n",
        "    metrics[\"technique\"] = technique_name\n",
        "    results_all.append(metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d6376f2",
      "metadata": {
        "id": "0d6376f2"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame(results_all)\n",
        "results_df = results_df.sort_values(\"f1\", ascending=False)\n",
        "\n",
        "# Print\n",
        "print(results_df[[\"technique\",\"accuracy\",\"precision\",\"recall\",\"f1\"]])\n",
        "\n",
        "# Confusion matrices\n",
        "for idx, row in results_df.iterrows():\n",
        "    cm = confusion_matrix(row[\"y_true\"], row[\"y_pred\"], labels=[0,1])\n",
        "    plt.figure(figsize=(5,4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"oppose\",\"support\"], yticklabels=[\"oppose\",\"support\"])\n",
        "    plt.title(f\"Confusion Matrix - {row['technique']}\\nF1: {row['f1']:.4f}\")\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "multimodal",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}