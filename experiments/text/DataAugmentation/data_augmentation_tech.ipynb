{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dcfe4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diego\\anaconda3\\envs\\multimodal\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data locally from: C:/Users/diego/Desktop/Master Neuro/M2/Intership_NLP/multimodal-argmining\n",
      "No GPU detecting, using CPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\diego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\diego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\diego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from datasets import Dataset\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nlpaug.augmenter.word as naw\n",
    "from googletrans import Translator\n",
    "import random, time\n",
    "import sentencepiece\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, T5Tokenizer, Trainer, TrainingArguments, EarlyStoppingCallback, AutoModelForSequenceClassification\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Google Colab or not\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    path = \"/content/drive/MyDrive/multimodal-argmining\"\n",
    "    os.chdir(path)\n",
    "    print(f\"Loading data from Google Drive: {path}\")\n",
    "else:\n",
    "    path = \"C:/Users/diego/Desktop/Master Neuro/M2/Intership_NLP/multimodal-argmining\"\n",
    "    os.chdir(path)\n",
    "    print(f\"Loading data locally from: {path}\")\n",
    "\n",
    "\n",
    "# GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU ready:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU detecting, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc7c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"roberta-base\"  # wE CAn change this to any model you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9ffdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dataset\n",
    "train_path = f\"{path}/data/train.csv\"\n",
    "dev_path   = f\"{path}/data/dev.csv\"\n",
    "test_path  = f\"{path}/data/test.csv\"\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_dev   = pd.read_csv(dev_path)\n",
    "df_test  = pd.read_csv(test_path)\n",
    "\n",
    "\n",
    "# Map labels to ints\n",
    "label2id = {\"oppose\": 0, \"support\": 1}\n",
    "for df in [df_train, df_dev, df_test]:\n",
    "    df[\"label\"] = df[\"stance\"].map(label2id)\n",
    "\n",
    "df_train.head()\n",
    "\n",
    "\n",
    "dataset_train = Dataset.from_pandas(df_train[[\"tweet_text\", \"label\"]])\n",
    "dataset_dev   = Dataset.from_pandas(df_dev[[\"tweet_text\", \"label\"]])\n",
    "dataset_test  = Dataset.from_pandas(df_test[[\"tweet_text\", \"label\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0122bfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class distribution:\n",
      "Stance value counts:\n",
      " stance\n",
      "oppose     1095\n",
      "support     719\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Train class distribution:\")\n",
    "stance_counts = df_train['stance'].value_counts()\n",
    "print(\"Stance value counts:\\n\", stance_counts)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=stance_counts.index, y=stance_counts.values, palette=\"viridis\")\n",
    "plt.title(\"Stance Distribution - Train Set \")\n",
    "plt.ylabel(\"Number of Tweets\")\n",
    "plt.xlabel(\"Stance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea55ef6e",
   "metadata": {},
   "source": [
    "## Data Augmentation Techniques "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810c85c9",
   "metadata": {},
   "source": [
    "### Synonym Replacement (WordNet)\n",
    "\n",
    "This technique randomly selects words in a sentence (excluding stop words) and replaces them with synonyms obtained from a lexical database like WordNet. The goal is to create semantically similar sentences without changing the meaning.  \n",
    "\n",
    "**Example:**  \n",
    "Original: \"Gun control laws should be stricter to reduce crime.\"  \n",
    "Augmented: \"Firearm regulation rules should be tougher to reduce crime.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9e9b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_synonym(texts, n=1):\n",
    "    aug = naw.SynonymAug(aug_p=0.2) #aug_p = probability of words to be augmented.\n",
    "    augmented = [aug.augment(t) for t in texts for _ in range(n)]\n",
    "    return augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28d9bd7",
   "metadata": {},
   "source": [
    "### Back Translation\n",
    "\n",
    "Back translation involves translating a sentence to another language and then translating it back to the original language. This introduces natural paraphrases and linguistic variations.  \n",
    "\n",
    "**Example:**  \n",
    "Original: \"We need stronger gun regulations.\"  \n",
    "Augmented: \"It is necessary to have stricter firearm laws.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851f0b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_translate(texts, n=1, sleep_time=0.3):\n",
    "    translator = Translator()\n",
    "    augmented = []\n",
    "    for t in texts:\n",
    "        try:\n",
    "            fr = translator.translate(t, src=\"en\", dest=\"fr\").text\n",
    "            back = translator.translate(fr, src=\"fr\", dest=\"en\").text\n",
    "            augmented.append(back)\n",
    "            time.sleep(sleep_time)\n",
    "        except:\n",
    "            continue\n",
    "    return augmented\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3cba25",
   "metadata": {},
   "source": [
    "### Paraphrasing with T5 / Pegasus\n",
    "\n",
    "Paraphrasing models (like T5 or Pegasus) generate alternative ways of writing a sentence while preserving its meaning. These models are trained on large datasets of paraphrase pairs.  \n",
    "\n",
    "**Example:**  \n",
    "Original: \"The Second Amendment should be reconsidered.\"  \n",
    "Augmented: \"We should rethink the Second Amendment.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02551799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\", use_fast=False)\n",
    "para_tokenizer = AutoTokenizer.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")\n",
    "para_model = AutoModelForSeq2SeqLM.from_pretrained(\"Vamsi/T5_Paraphrase_Paws\")\n",
    "\n",
    "def augment_paraphrase(texts, n=1):\n",
    "    augmented = []\n",
    "    for t in texts:\n",
    "        input_text = f\"paraphrase: {t} </s>\"\n",
    "        encoding = para_tokenizer.encode_plus(input_text, return_tensors=\"pt\", truncation=True)\n",
    "        outputs = para_model.generate(\n",
    "            **encoding, max_length=128, num_beams=5, num_return_sequences=n\n",
    "        )\n",
    "        for output in outputs:\n",
    "            augmented.append(para_tokenizer.decode(output, skip_special_tokens=True))\n",
    "    return augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7c805c",
   "metadata": {},
   "source": [
    "### Noise Injection\n",
    "\n",
    "Randomly removes or inserts words in a sentence, introducing small perturbations. This simulates noisy text, such as typos or incomplete sentences.  \n",
    "\n",
    "**Example:**  \n",
    "Original: \"Gun control laws need to be enforced strictly.\"  \n",
    "Augmented: \"Gun laws need enforced strictly.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f41279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_noise(texts, del_prob=0.1):\n",
    "    augmented = []\n",
    "    for t in texts:\n",
    "        words = t.split()\n",
    "        new_words = [w for w in words if random.random() > del_prob]\n",
    "        augmented.append(\" \".join(new_words))\n",
    "    return augmented\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efa5986",
   "metadata": {},
   "source": [
    "## Generate our Augmented Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9077cd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df_train[df_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(minority_df)\n\u001b[0;32m      3\u001b[0m texts_to_augment \u001b[38;5;241m=\u001b[39m minority_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      5\u001b[0m augmentations \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msynonym\u001b[39m\u001b[38;5;124m\"\u001b[39m: augment_synonym(texts_to_augment),\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mback_translation\u001b[39m\u001b[38;5;124m\"\u001b[39m: back_translate(texts_to_augment),\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparaphrase\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43maugment_paraphrase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts_to_augment\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnoise\u001b[39m\u001b[38;5;124m\"\u001b[39m: augment_noise(texts_to_augment)\n\u001b[0;32m     10\u001b[0m }\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Guardamos nuevos datasets balanceados\u001b[39;00m\n\u001b[0;32m     13\u001b[0m augmented_datasets \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m, in \u001b[0;36maugment_paraphrase\u001b[1;34m(texts, n)\u001b[0m\n\u001b[0;32m      8\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparaphrase: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m </s>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m encoding \u001b[38;5;241m=\u001b[39m para_tokenizer\u001b[38;5;241m.\u001b[39mencode_plus(input_text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m para_model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoding, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, num_beams\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, num_return_sequences\u001b[38;5;241m=\u001b[39mn\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs:\n\u001b[0;32m     14\u001b[0m     augmented\u001b[38;5;241m.\u001b[39mappend(para_tokenizer\u001b[38;5;241m.\u001b[39mdecode(output, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\diego\\anaconda3\\envs\\multimodal\\lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\diego\\anaconda3\\envs\\multimodal\\lib\\site-packages\\transformers\\generation\\utils.py:2564\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[0;32m   2561\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m generation_config\u001b[38;5;241m.\u001b[39muse_cache\n\u001b[0;32m   2563\u001b[0m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[1;32m-> 2564\u001b[0m result \u001b[38;5;241m=\u001b[39m decoding_method(\n\u001b[0;32m   2565\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2566\u001b[0m     input_ids,\n\u001b[0;32m   2567\u001b[0m     logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2568\u001b[0m     stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2569\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2570\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgeneration_mode_kwargs,\n\u001b[0;32m   2571\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2572\u001b[0m )\n\u001b[0;32m   2574\u001b[0m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[0;32m   2575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2576\u001b[0m     generation_config\u001b[38;5;241m.\u001b[39mreturn_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2577\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2578\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result\u001b[38;5;241m.\u001b[39mpast_key_values, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_legacy_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2579\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\diego\\anaconda3\\envs\\multimodal\\lib\\site-packages\\transformers\\generation\\utils.py:3377\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   3375\u001b[0m         model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reorder_cache(model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m], beam_idx)\n\u001b[0;32m   3376\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3377\u001b[0m         \u001b[43mmodel_kwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpast_key_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreorder_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3379\u001b[0m cur_len \u001b[38;5;241m=\u001b[39m cur_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   3380\u001b[0m is_early_stop_heuristic_unsatisfied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_early_stop_heuristic(\n\u001b[0;32m   3381\u001b[0m     is_early_stop_heuristic_unsatisfied\u001b[38;5;241m=\u001b[39mis_early_stop_heuristic_unsatisfied,\n\u001b[0;32m   3382\u001b[0m     running_beam_scores\u001b[38;5;241m=\u001b[39mrunning_beam_scores,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3389\u001b[0m     length_penalty\u001b[38;5;241m=\u001b[39mlength_penalty,\n\u001b[0;32m   3390\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\diego\\anaconda3\\envs\\multimodal\\lib\\site-packages\\transformers\\cache_utils.py:1309\u001b[0m, in \u001b[0;36mEncoderDecoderCache.reorder_cache\u001b[1;34m(self, beam_idx)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reorders the cache for beam search, given the selected beam indices.\"\"\"\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attention_cache\u001b[38;5;241m.\u001b[39mreorder_cache(beam_idx)\n\u001b[1;32m-> 1309\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_attention_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreorder_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\diego\\anaconda3\\envs\\multimodal\\lib\\site-packages\\transformers\\cache_utils.py:832\u001b[0m, in \u001b[0;36mCache.reorder_cache\u001b[1;34m(self, beam_idx)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reorder the cache for beam search\"\"\"\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers)):\n\u001b[1;32m--> 832\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreorder_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\diego\\anaconda3\\envs\\multimodal\\lib\\site-packages\\transformers\\cache_utils.py:80\u001b[0m, in \u001b[0;36mCacheLayerMixin.reorder_cache\u001b[1;34m(self, beam_idx)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reorders this layer's cache for beam search.\"\"\"\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_seq_length() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mindex_select(\u001b[38;5;241m0\u001b[39m, beam_idx\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdevice))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "minority_df = df_train[df_train[\"label\"] == 1]\n",
    "n_samples = len(df_train[df_train[\"label\"] == 0]) - len(minority_df)\n",
    "texts_to_augment = minority_df[\"tweet_text\"].tolist()\n",
    "\n",
    "augmentations = {\n",
    "    \"synonym\": augment_synonym,\n",
    "    \"back_translation\": back_translate,\n",
    "    \"paraphrase\": augment_paraphrase,\n",
    "    \"noise\": augment_noise\n",
    "}\n",
    "\n",
    "# Generate our augmented datasets\n",
    "augmented_datasets = {}\n",
    "\n",
    "for name, func in augmentations.items():\n",
    "    print(f\"Generating dataset with technique: {name}...\")\n",
    "\n",
    "    augmented_texts = func(texts_to_augment[:n_samples])\n",
    "    #augmented_texts = augmented_texts[:n_samples]\n",
    "    \n",
    "    new_df = pd.concat([\n",
    "        df_train,\n",
    "        pd.DataFrame({\n",
    "            \"tweet_text\": augmented_texts,\n",
    "            \"stance\": \"support\",\n",
    "            \"label\": 1\n",
    "        })\n",
    "    ], ignore_index=True)\n",
    "    \n",
    "    augmented_datasets[name] = new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7459ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize augmented datasets distribution\n",
    "for name, df_aug in augmented_datasets.items():\n",
    "    stance_counts = df_aug['stance'].value_counts()\n",
    "    \n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.barplot(x=stance_counts.index, y=stance_counts.values, palette=\"viridis\")\n",
    "    plt.title(f\"Stance Distribution - {name.capitalize()} Augmentation\")\n",
    "    plt.ylabel(\"Number of Tweets\")\n",
    "    plt.xlabel(\"Stance\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101af04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics we are going to evaluate\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"macro\"),\n",
    "        \"precision\": precision_score(labels, preds, average=\"macro\"),\n",
    "        \"recall\": recall_score(labels, preds, average=\"macro\")\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c82c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tokenization Function for each model\n",
    "def tokenize_dataset(dataset, tokenizer, max_length=105):\n",
    "\n",
    "    def tokenize_batch(batch):\n",
    "        return tokenizer(batch[\"tweet_text\"],padding=\"max_length\",truncation=True,max_length=max_length)\n",
    "\n",
    "    tokenized = dataset.map(tokenize_batch, batched=True)\n",
    "\n",
    "    tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dc3d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate function\n",
    "def train_and_evaluate(model_name, train_dataset, dev_dataset, test_dataset, seed=42, max_len=105):\n",
    "    \n",
    "    #Set Seed\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    print(f\"Tokenizer loaded for {model_name}...\")\n",
    "\n",
    "    # Tokenize datasets with model tokenizer\n",
    "    train_dataset_tok = tokenize_dataset(train_dataset, tokenizer, 105)\n",
    "    dev_dataset_tok = tokenize_dataset(dev_dataset, tokenizer, 105)\n",
    "    test_dataset_tok = tokenize_dataset(test_dataset, tokenizer, 105)\n",
    "    print(f\"Tokenization complete\")    \n",
    "\n",
    "    # Load model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "    print(f\"Model Loaded: {model_name}.\")\n",
    "\n",
    "\n",
    "    # TrainingArguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./temp_models/{model_name.replace('/', '_')}_seed{seed}\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"no\", \n",
    "        logging_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=5,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        report_to=\"none\",\n",
    "        logging_steps=10\n",
    "    )\n",
    "\n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset_tok,\n",
    "        eval_dataset=dev_dataset_tok,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    print(f\"\\n Starting training...\")\n",
    "    trainer.train()\n",
    "\n",
    "    # Predictions on TEST set\n",
    "    print(f\"\\n Getting predictions on TEST set...\")\n",
    "    predictions_output = trainer.predict(test_dataset_tok)\n",
    "    y_pred = np.argmax(predictions_output.predictions, axis=1)\n",
    "    y_true = predictions_output.label_ids\n",
    "\n",
    "\n",
    "    # Metrics\n",
    "    metrics = compute_metrics(predictions_output)\n",
    "    metrics[\"y_true\"] = y_true\n",
    "    metrics[\"y_pred\"] = y_pred\n",
    "\n",
    "    print(f\"\\n Results for {model_name}:\")\n",
    "    print(f\"   Accuracy:  {metrics['accuracy']:.4f}\")\n",
    "    print(f\"   Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"   Recall:    {metrics['recall']:.4f}\")\n",
    "    print(f\"   F1-Score:  {metrics['f1']:.4f}\")\n",
    "\n",
    "    # Cleanup\n",
    "    del model, trainer, train_dataset_tok, dev_dataset_tok, test_dataset_tok\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e171904",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all = []\n",
    "\n",
    "for technique_name, df_aug in augmented_datasets.items():\n",
    "    print(f\"\\nTraining with augmentation: {technique_name}\")\n",
    "    dataset_aug = Dataset.from_pandas(df_aug[[\"tweet_text\",\"label\"]])\n",
    "\n",
    "    metrics = train_and_evaluate(\n",
    "        model_name=MODEL_NAME,\n",
    "        train_dataset=dataset_aug,\n",
    "        dev_dataset=dataset_dev,\n",
    "        test_dataset=dataset_test,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    metrics[\"technique\"] = technique_name\n",
    "    results_all.append(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6376f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_all)\n",
    "results_df = results_df.sort_values(\"f1\", ascending=False)\n",
    "\n",
    "# Print\n",
    "print(results_df[[\"technique\",\"accuracy\",\"precision\",\"recall\",\"f1\"]])\n",
    "\n",
    "# Confusion matrices\n",
    "for idx, row in results_df.iterrows():\n",
    "    cm = confusion_matrix(row[\"y_true\"], row[\"y_pred\"], labels=[0,1])\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"oppose\",\"support\"], yticklabels=[\"oppose\",\"support\"])\n",
    "    plt.title(f\"Confusion Matrix - {row['technique']}\\nF1: {row['f1']:.4f}\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
