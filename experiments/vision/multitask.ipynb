{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b3af112",
   "metadata": {},
   "source": [
    "### Image Preprocessing Pipeline for Multi-Task (Stance,Persuasiveness) Classification\n",
    "\n",
    "This notebook prepares the image data pipeline for multi-task learning, where we want to simultaneously predict:\n",
    "1. Persuasiveness: Whether the image contributes to the argument (binary)\n",
    "2. Stance: The position towards gun control/abortion (support/oppose)\n",
    "\n",
    "Multitask learning (MTL) is particularly effective when:\n",
    "- Tasks are related and share unerlying structure\n",
    "- Dataset has irrelevant samples\n",
    "- One task is easier and can guide learning of harder task\n",
    "- Limited data is available \n",
    "   \n",
    "Our scenario satisfies ALL these conditions:\n",
    "a) Related tasks: Persuasiveness and stance are highly correlated: A persuasive image typically has clear stance indicators\n",
    "b) Auxiliary task benefit. Model learns: \"Is this image relevant?\" then \"What's the stance?\" (Similar to human reasoning process)\n",
    "c) Regularization effect. The MTL architecture prevents overfitting by forcing encoder to learn general visual features useful for both tasks.\n",
    "\n",
    "Our Problem: If we train a single task (stance only), the model tries to learn stance from ALL images, including irrelevant ones (with no useful information)\n",
    "Solution: Multi-task learning explicitly teaches the model to:\n",
    "   1. Identify which images are relevant (persuasiveness)\n",
    "   2. Then predict stance from relevant images\n",
    "   \n",
    "In our final multimodal model, persuasiveness predictions serve as confidence weights:\n",
    "final_prediction = α * text_prediction + β * (persuasiveness * image_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ca9da1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11573246",
   "metadata": {},
   "source": [
    "Grad-CAM\n",
    "¿Qué es?\n",
    "\n",
    "Es una técnica para ver qué partes de la imagen activaron el cerebro del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30334b7c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
